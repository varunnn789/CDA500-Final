{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd038bf-8550-420b-9ec2-308198fca80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import src.config as config\n",
    "from src.inference import get_feature_store\n",
    "from src.data_utils import transform_ts_data_info_features\n",
    "from src.inference import load_model_from_registry\n",
    "from src.inference import get_model_predictions\n",
    "from src.inference import get_feature_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb543707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "2025-05-10 04:52:18,053 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 04:52:18,059 INFO: Initializing external client\n",
      "2025-05-10 04:52:18,059 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:52:18,746 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Error creating feature view: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/1225907/featurestores/1212511/featureview). Server response: \n",
      "HTTP code: 400, HTTP reason: Bad Request, body: b'{\"errorCode\":270179,\"usrMsg\":\"Feature view: citi_bike_recent_hourly_feature_view, version: 1\",\"errorMsg\":\"The provided feature view name and version already exists\"}', error code: 270179, error msg: The provided feature view name and version already exists, user msg: Feature view: citi_bike_recent_hourly_feature_view, version: 1\n",
      "Current date: 2025-05-10 08:52:21.159984+00:00\n",
      "Fetching data from 2025-04-11 08:52:21.159984+00:00 to 2025-05-10 08:00:00+00:00\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.62s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-11 09:00:00+00:00</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-11 10:00:00+00:00</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-11 11:00:00+00:00</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-11 12:00:00+00:00</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-11 13:00:00+00:00</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>2025-05-10 03:00:00+00:00</td>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>2025-05-10 04:00:00+00:00</td>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>2025-05-10 05:00:00+00:00</td>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>2025-05-10 06:00:00+00:00</td>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>2025-05-10 07:00:00+00:00</td>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2085 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pickup_hour start_station_name  rides\n",
       "0    2025-04-11 09:00:00+00:00   11 Ave & W 41 St     16\n",
       "1    2025-04-11 10:00:00+00:00   11 Ave & W 41 St     14\n",
       "2    2025-04-11 11:00:00+00:00   11 Ave & W 41 St      7\n",
       "3    2025-04-11 12:00:00+00:00   11 Ave & W 41 St     14\n",
       "4    2025-04-11 13:00:00+00:00   11 Ave & W 41 St     12\n",
       "...                        ...                ...    ...\n",
       "2080 2025-05-10 03:00:00+00:00    W 31 St & 7 Ave      0\n",
       "2081 2025-05-10 04:00:00+00:00    W 31 St & 7 Ave      1\n",
       "2082 2025-05-10 05:00:00+00:00    W 31 St & 7 Ave      1\n",
       "2083 2025-05-10 06:00:00+00:00    W 31 St & 7 Ave     10\n",
       "2084 2025-05-10 07:00:00+00:00    W 31 St & 7 Ave      5\n",
       "\n",
       "[2085 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2085 entries, 0 to 2099\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype                  \n",
      "---  ------              --------------  -----                  \n",
      " 0   pickup_hour         2085 non-null   datetime64[us, Etc/UTC]\n",
      " 1   start_station_name  2085 non-null   object                 \n",
      " 2   rides               2085 non-null   int32                  \n",
      "dtypes: datetime64[us, Etc/UTC](1), int32(1), object(1)\n",
      "memory usage: 57.0+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2085 entries, 0 to 2099\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   pickup_hour         2085 non-null   datetime64[us]\n",
      " 1   start_station_name  2085 non-null   object        \n",
      " 2   rides               2085 non-null   int32         \n",
      "dtypes: datetime64[us](1), int32(1), object(1)\n",
      "memory usage: 57.0+ KB\n",
      "\n",
      "ts_data (after filtering):\n",
      "Shape: (2085, 3)\n",
      "pickup_hour range: 2025-04-11 09:00:00 to 2025-05-10 07:00:00\n",
      "             pickup_hour start_station_name  rides\n",
      "0    2025-04-26 22:00:00    W 21 St & 6 Ave      1\n",
      "1    2025-04-18 18:00:00    W 21 St & 6 Ave     14\n",
      "2    2025-04-16 16:00:00   11 Ave & W 41 St      8\n",
      "3    2025-04-14 00:00:00    W 31 St & 7 Ave      0\n",
      "4    2025-05-09 01:00:00    W 21 St & 6 Ave      1\n",
      "...                  ...                ...    ...\n",
      "2095 2025-05-10 06:00:00   11 Ave & W 41 St      2\n",
      "2096 2025-05-10 06:00:00    W 31 St & 7 Ave     10\n",
      "2097 2025-05-10 07:00:00   11 Ave & W 41 St      7\n",
      "2098 2025-05-10 07:00:00    W 31 St & 7 Ave      5\n",
      "2099 2025-05-10 07:00:00    W 21 St & 6 Ave      2\n",
      "\n",
      "[2085 rows x 3 columns]\n",
      "\n",
      "Most recent hour in features_next_hour: 2025-05-10 07:00:00\n",
      "\n",
      "features_next_hour:\n",
      "Shape: (3, 674)\n",
      "  start_station_name  rides_t-672  rides_t-671  rides_t-670  rides_t-669  \\\n",
      "0   11 Ave & W 41 St            2            6           10           15   \n",
      "1    W 21 St & 6 Ave            1            6            4            9   \n",
      "2    W 31 St & 7 Ave            3            0            2            3   \n",
      "\n",
      "   rides_t-668  rides_t-667  rides_t-666  rides_t-665  rides_t-664  ...  \\\n",
      "0            7           15           10            8           14  ...   \n",
      "1            6           14           20            9           12  ...   \n",
      "2            4            6            6           16            9  ...   \n",
      "\n",
      "   rides_t-9  rides_t-8  rides_t-7  rides_t-6  rides_t-5  rides_t-4  \\\n",
      "0          6          6          5          1          2          0   \n",
      "1          6          7          1          9          2          0   \n",
      "2         14          4          1          2          1          0   \n",
      "\n",
      "   rides_t-3  rides_t-2  rides_t-1         pickup_hour  \n",
      "0          2          0          2 2025-05-10 07:00:00  \n",
      "1          1          1          3 2025-05-10 07:00:00  \n",
      "2          1          1         10 2025-05-10 07:00:00  \n",
      "\n",
      "[3 rows x 674 columns]\n",
      "\n",
      "Processing model: baseline_previous_hour\n",
      "2025-05-10 04:52:23,802 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 04:52:23,808 INFO: Initializing external client\n",
      "2025-05-10 04:52:23,808 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:52:24,413 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Downloading model artifact (0 dirs, 1 files)... DONE\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>predicted_rides</th>\n",
       "      <th>pickup_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-05-10 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W 21 St &amp; 6 Ave</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-05-10 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-05-10 07:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_station_name  predicted_rides         pickup_hour\n",
       "0   11 Ave & W 41 St                2 2025-05-10 07:00:00\n",
       "1    W 21 St & 6 Ave                3 2025-05-10 07:00:00\n",
       "2    W 31 St & 7 Ave               10 2025-05-10 07:00:00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Rows 3/3 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: predictions_model_baseline_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1225907/jobs/named/predictions_model_baseline_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('predictions_model_baseline_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to feature group: predictions_model_baseline\n",
      "\n",
      "Processing model: lightgbm_28days_lags\n",
      "2025-05-10 04:52:35,476 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 04:52:35,487 INFO: Initializing external client\n",
      "2025-05-10 04:52:35,487 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:52:36,139 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Downloading model artifact (0 dirs, 1 files)... DONE\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>predicted_rides</th>\n",
       "      <th>pickup_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2025-05-10 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W 21 St &amp; 6 Ave</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2025-05-10 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2025-05-10 07:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_station_name  predicted_rides         pickup_hour\n",
       "0   11 Ave & W 41 St              2.0 2025-05-10 07:00:00\n",
       "1    W 21 St & 6 Ave              1.0 2025-05-10 07:00:00\n",
       "2    W 31 St & 7 Ave              5.0 2025-05-10 07:00:00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Rows 3/3 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: predictions_model_lgbm_28days_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1225907/jobs/named/predictions_model_lgbm_28days_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('predictions_model_lgbm_28days_1_offline_fg_materialization', 'SPARK'),\n",
       " None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to feature group: predictions_model_lgbm_28days\n",
      "\n",
      "Processing model: lightgbm_top10_features\n",
      "2025-05-10 04:52:47,802 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 04:52:47,808 INFO: Initializing external client\n",
      "2025-05-10 04:52:47,809 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:52:48,559 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Downloading model artifact (0 dirs, 1 files)... DONE\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>predicted_rides</th>\n",
       "      <th>pickup_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2025-05-10 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W 21 St &amp; 6 Ave</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2025-05-10 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2025-05-10 07:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_station_name  predicted_rides         pickup_hour\n",
       "0   11 Ave & W 41 St              6.0 2025-05-10 07:00:00\n",
       "1    W 21 St & 6 Ave              3.0 2025-05-10 07:00:00\n",
       "2    W 31 St & 7 Ave              9.0 2025-05-10 07:00:00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Rows 3/3 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: predictions_model_lgbm_top10_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1225907/jobs/named/predictions_model_lgbm_top10_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('predictions_model_lgbm_top10_1_offline_fg_materialization', 'SPARK'),\n",
       " None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to feature group: predictions_model_lgbm_top10\n",
      "\n",
      "Processing model: gradient_boosting_temporal_features\n",
      "2025-05-10 04:53:02,724 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 04:53:02,730 INFO: Initializing external client\n",
      "2025-05-10 04:53:02,731 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:53:03,354 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Downloading model artifact (0 dirs, 1 files)... DONE\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>predicted_rides</th>\n",
       "      <th>pickup_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2025-05-10 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W 21 St &amp; 6 Ave</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2025-05-10 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2025-05-10 07:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_station_name  predicted_rides         pickup_hour\n",
       "0   11 Ave & W 41 St              7.0 2025-05-10 07:00:00\n",
       "1    W 21 St & 6 Ave              4.0 2025-05-10 07:00:00\n",
       "2    W 31 St & 7 Ave              7.0 2025-05-10 07:00:00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Rows 3/3 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: predictions_model_gbt_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1225907/jobs/named/predictions_model_gbt_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('predictions_model_gbt_1_offline_fg_materialization', 'SPARK'), None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to feature group: predictions_model_gbt\n",
      "\n",
      "Processing model: lightgbm_enhanced_lags_cyclic_temporal_interactions\n",
      "2025-05-10 04:53:14,396 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 04:53:14,403 INFO: Initializing external client\n",
      "2025-05-10 04:53:14,404 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:53:15,077 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Downloading model artifact (0 dirs, 1 files)... DONE\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>predicted_rides</th>\n",
       "      <th>pickup_hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2025-05-10 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W 21 St &amp; 6 Ave</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2025-05-10 07:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2025-05-10 07:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_station_name  predicted_rides         pickup_hour\n",
       "0   11 Ave & W 41 St              8.0 2025-05-10 07:00:00\n",
       "1    W 21 St & 6 Ave              5.0 2025-05-10 07:00:00\n",
       "2    W 31 St & 7 Ave             11.0 2025-05-10 07:00:00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Rows 3/3 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: predictions_model_lgbm_enhanced_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1225907/jobs/named/predictions_model_lgbm_enhanced_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('predictions_model_lgbm_enhanced_1_offline_fg_materialization', 'SPARK'),\n",
       " None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to feature group: predictions_model_lgbm_enhanced\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import src.config as config\n",
    "from src.inference import get_feature_store\n",
    "from src.data_utils import transform_ts_data_info_features\n",
    "from src.inference import load_batch_of_features_from_store\n",
    "from src.inference import load_model_from_registry\n",
    "from src.inference import get_model_predictions\n",
    "from src.inference import BaselineModelPreviousHour\n",
    "\n",
    "# Connect to Hopsworks and get the feature store\n",
    "feature_store = get_feature_store()\n",
    "\n",
    "# Retrieve the feature group with recent data\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=\"recent_time_series_hourly_feature_group\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Create or retrieve the feature view for recent data\n",
    "try:\n",
    "    feature_store.create_feature_view(\n",
    "        name=\"citi_bike_recent_hourly_feature_view\",\n",
    "        version=1,\n",
    "        query=feature_group.select_all(),\n",
    "    )\n",
    "    print(f\"Feature view 'citi_bike_recent_hourly_feature_view' (version 1) created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating feature view: {e}\")\n",
    "\n",
    "feature_view = feature_store.get_feature_view(\n",
    "    name=\"citi_bike_recent_hourly_feature_view\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Get the current datetime\n",
    "current_date = pd.Timestamp.now(tz='Etc/UTC')\n",
    "print(f\"Current date: {current_date}\")\n",
    "\n",
    "# Read time-series data from the feature store\n",
    "fetch_data_to = current_date.floor('h')  # Include the current hour\n",
    "fetch_data_from = current_date - timedelta(days=1*29)\n",
    "print(f\"Fetching data from {fetch_data_from} to {fetch_data_to}\")\n",
    "\n",
    "ts_data = feature_view.get_batch_data(\n",
    "    start_time=(fetch_data_from - timedelta(days=1)),\n",
    "    end_time=(fetch_data_to + timedelta(days=1)),\n",
    ")\n",
    "ts_data = ts_data[ts_data.pickup_hour.between(fetch_data_from, fetch_data_to)]\n",
    "ts_data.sort_values([\"start_station_name\", \"pickup_hour\"]).reset_index(drop=True)\n",
    "ts_data.info()\n",
    "\n",
    "ts_data[\"pickup_hour\"] = ts_data[\"pickup_hour\"].dt.tz_localize(None)\n",
    "ts_data.info()\n",
    "\n",
    "# Debugging: Print ts_data to inspect pickup_hour range\n",
    "print(\"\\nts_data (after filtering):\")\n",
    "print(\"Shape:\", ts_data.shape)\n",
    "print(\"pickup_hour range:\", ts_data[\"pickup_hour\"].min(), \"to\", ts_data[\"pickup_hour\"].max())\n",
    "print(ts_data)\n",
    "\n",
    "# Transform the data into features\n",
    "features = transform_ts_data_info_features(ts_data, window_size=24*28, step_size=23)\n",
    "\n",
    "# Sort features by pickup_hour in descending order to ensure the most recent hour is selected\n",
    "features.sort_values(\"pickup_hour\", ascending=False, inplace=True)\n",
    "\n",
    "# Filter features for the most recent hour\n",
    "features_next_hour = features.groupby(\"start_station_name\").first().reset_index()\n",
    "recent_hour = features_next_hour[\"pickup_hour\"].max()\n",
    "print(f\"\\nMost recent hour in features_next_hour: {recent_hour}\")\n",
    "\n",
    "# Debugging: Print features_next_hour\n",
    "print(\"\\nfeatures_next_hour:\")\n",
    "print(\"Shape:\", features_next_hour.shape)\n",
    "print(features_next_hour)\n",
    "\n",
    "# Define the list of models and corresponding feature group names\n",
    "models = [\n",
    "    \"baseline_previous_hour\",\n",
    "    \"lightgbm_28days_lags\",\n",
    "    \"lightgbm_top10_features\",\n",
    "    \"gradient_boosting_temporal_features\",\n",
    "    \"lightgbm_enhanced_lags_cyclic_temporal_interactions\"\n",
    "]\n",
    "\n",
    "prediction_feature_groups = {\n",
    "    \"baseline_previous_hour\": \"predictions_model_baseline\",\n",
    "    \"lightgbm_28days_lags\": \"predictions_model_lgbm_28days\",\n",
    "    \"lightgbm_top10_features\": \"predictions_model_lgbm_top10\",\n",
    "    \"gradient_boosting_temporal_features\": \"predictions_model_gbt\",\n",
    "    \"lightgbm_enhanced_lags_cyclic_temporal_interactions\": \"predictions_model_lgbm_enhanced\"\n",
    "}\n",
    "\n",
    "# Make predictions with each model and save to separate feature groups\n",
    "for model_name in models:\n",
    "    print(f\"\\nProcessing model: {model_name}\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model_from_registry(model_name=model_name)\n",
    "    \n",
    "    # Make predictions for the most recent hour\n",
    "    predictions = get_model_predictions(model, features_next_hour, model_name=model_name)\n",
    "    predictions[\"pickup_hour\"] = recent_hour  # Use the most recent actual hour\n",
    "    predictions\n",
    "    \n",
    "    # Create or retrieve the feature group for this model's predictions\n",
    "    feature_group = feature_store.get_or_create_feature_group(\n",
    "        name=prediction_feature_groups[model_name],\n",
    "        version=1,\n",
    "        description=f\"Predictions from {model_name} model\",\n",
    "        primary_key=[\"start_station_name\", \"pickup_hour\"],\n",
    "        event_time=\"pickup_hour\",\n",
    "    )\n",
    "    \n",
    "    # Insert the predictions into the feature group\n",
    "    feature_group.insert(predictions, write_options={\"wait_for_job\": False})\n",
    "    print(f\"Saved predictions to feature group: {prediction_feature_groups[model_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f033e779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "2025-05-10 06:10:33,814 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:10:33,819 INFO: Initializing external client\n",
      "2025-05-10 06:10:33,821 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 06:10:34,518 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Current date: 2025-05-10 10:10:35.140489+00:00\n",
      "Current hour: 2025-05-10 10:00:00+00:00\n",
      "Adjusted start_hour: 2025-04-11 11:00:00+00:00\n",
      "End hour (before adjustment): 2025-05-10 10:00:00+00:00\n",
      "Fetching data from 2025-03-14 11:00:00+00:00 to 2025-05-10 10:00:00+00:00\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.56s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-11 08:00:00</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-11 09:00:00</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-11 10:00:00</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-11 11:00:00</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-11 12:00:00</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>2025-05-10 02:00:00</td>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356</th>\n",
       "      <td>2025-05-10 03:00:00</td>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>2025-05-10 04:00:00</td>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>2025-05-10 05:00:00</td>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3359</th>\n",
       "      <td>2025-05-10 06:00:00</td>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3360 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pickup_hour start_station_name  rides\n",
       "0    2025-04-11 08:00:00   11 Ave & W 41 St     16\n",
       "1    2025-04-11 09:00:00   11 Ave & W 41 St     16\n",
       "2    2025-04-11 10:00:00   11 Ave & W 41 St     14\n",
       "3    2025-04-11 11:00:00   11 Ave & W 41 St      7\n",
       "4    2025-04-11 12:00:00   11 Ave & W 41 St     14\n",
       "...                  ...                ...    ...\n",
       "3355 2025-05-10 02:00:00    W 31 St & 7 Ave      1\n",
       "3356 2025-05-10 03:00:00    W 31 St & 7 Ave      0\n",
       "3357 2025-05-10 04:00:00    W 31 St & 7 Ave      1\n",
       "3358 2025-05-10 05:00:00    W 31 St & 7 Ave      1\n",
       "3359 2025-05-10 06:00:00    W 31 St & 7 Ave     10\n",
       "\n",
       "[3360 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3360 entries, 0 to 3359\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   pickup_hour         3360 non-null   datetime64[us]\n",
      " 1   start_station_name  3360 non-null   object        \n",
      " 2   rides               3360 non-null   int32         \n",
      "dtypes: datetime64[us](1), int32(1), object(1)\n",
      "memory usage: 65.8+ KB\n",
      "\n",
      "ts_data (after filtering):\n",
      "Shape: (3360, 3)\n",
      "pickup_hour range: 2025-03-14 07:00:00 to 2025-05-10 06:00:00\n",
      "             pickup_hour       start_station_name  rides\n",
      "0    2025-03-14 12:00:00          W 21 St & 6 Ave     23\n",
      "1    2025-03-27 11:00:00          W 21 St & 6 Ave     25\n",
      "2    2025-03-16 02:00:00          8 Ave & W 31 St      2\n",
      "3    2025-03-19 03:00:00  University Pl & E 14 St      0\n",
      "4    2025-03-22 16:00:00          W 21 St & 6 Ave     28\n",
      "...                  ...                      ...    ...\n",
      "3355 2025-04-27 06:00:00         11 Ave & W 41 St      1\n",
      "3356 2025-04-17 12:00:00          W 21 St & 6 Ave      8\n",
      "3357 2025-05-10 05:00:00          W 31 St & 7 Ave      1\n",
      "3358 2025-04-14 21:00:00          W 31 St & 7 Ave      9\n",
      "3359 2025-04-24 09:00:00          W 21 St & 6 Ave     17\n",
      "\n",
      "[3360 rows x 3 columns]\n",
      "Adjusted end_hour to match ts_data: 2025-05-10 06:00:00\n",
      "Skipping station_name 8 Ave & W 31 St: Not enough data to create even one window.\n",
      "Skipping station_name University Pl & E 14 St: Not enough data to create even one window.\n",
      "\n",
      "features:\n",
      "Shape: (494, 674)\n",
      "pickup_hour range: 2025-04-21 15:00:00 to 2025-05-10 06:00:00\n",
      "    start_station_name         pickup_hour  rides_t-1\n",
      "0      W 21 St & 6 Ave 2025-05-10 06:00:00          1\n",
      "471   11 Ave & W 41 St 2025-05-10 06:00:00          0\n",
      "448    W 31 St & 7 Ave 2025-05-10 06:00:00          1\n",
      "1      W 21 St & 6 Ave 2025-05-10 05:00:00          1\n",
      "449    W 31 St & 7 Ave 2025-05-10 05:00:00          1\n",
      "..                 ...                 ...        ...\n",
      "443    W 21 St & 6 Ave 2025-04-21 19:00:00         25\n",
      "444    W 21 St & 6 Ave 2025-04-21 18:00:00         24\n",
      "445    W 21 St & 6 Ave 2025-04-21 17:00:00         28\n",
      "446    W 21 St & 6 Ave 2025-04-21 16:00:00         32\n",
      "447    W 21 St & 6 Ave 2025-04-21 15:00:00         27\n",
      "\n",
      "[494 rows x 3 columns]\n",
      "\n",
      "Generating predictions for hour: 2025-04-11 11:00:00\n",
      "No features found for 2025-04-11 11:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-11 12:00:00\n",
      "No features found for 2025-04-11 12:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-11 13:00:00\n",
      "No features found for 2025-04-11 13:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-11 14:00:00\n",
      "No features found for 2025-04-11 14:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-11 15:00:00\n",
      "No features found for 2025-04-11 15:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-11 16:00:00\n",
      "No features found for 2025-04-11 16:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-11 17:00:00\n",
      "No features found for 2025-04-11 17:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-11 18:00:00\n",
      "No features found for 2025-04-11 18:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-11 19:00:00\n",
      "No features found for 2025-04-11 19:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-11 20:00:00\n",
      "No features found for 2025-04-11 20:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-11 21:00:00\n",
      "No features found for 2025-04-11 21:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-11 22:00:00\n",
      "No features found for 2025-04-11 22:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-11 23:00:00\n",
      "No features found for 2025-04-11 23:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-12 00:00:00\n",
      "No features found for 2025-04-12 00:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-12 01:00:00\n",
      "No features found for 2025-04-12 01:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-12 02:00:00\n",
      "No features found for 2025-04-12 02:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-12 03:00:00\n",
      "No features found for 2025-04-12 03:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-12 04:00:00\n",
      "No features found for 2025-04-12 04:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-12 05:00:00\n",
      "No features found for 2025-04-12 05:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-12 06:00:00\n",
      "No features found for 2025-04-12 06:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-12 07:00:00\n",
      "No features found for 2025-04-12 07:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-12 08:00:00\n",
      "No features found for 2025-04-12 08:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-12 09:00:00\n",
      "No features found for 2025-04-12 09:00:00. Skipping.\n",
      "\n",
      "Generating predictions for hour: 2025-04-12 10:00:00\n",
      "No features found for 2025-04-12 10:00:00. Skipping.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No predictions were generated for any hour.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 154\u001b[0m\n\u001b[0;32m    152\u001b[0m     all_predictions_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_predictions, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo predictions were generated for any hour.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# Debugging: Print combined predictions\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll predictions combined:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: No predictions were generated for any hour."
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import src.config as config\n",
    "from src.inference import get_feature_store\n",
    "from src.data_utils import transform_ts_data_info_features\n",
    "from src.inference import load_batch_of_features_from_store\n",
    "from src.inference import load_model_from_registry\n",
    "from src.inference import get_model_predictions\n",
    "from src.inference import BaselineModelPreviousHour\n",
    "\n",
    "# Connect to Hopsworks and get the feature store\n",
    "feature_store = get_feature_store()\n",
    "\n",
    "# Get the current datetime\n",
    "current_date = pd.Timestamp.now(tz='Etc/UTC')\n",
    "current_hour = current_date.floor('h')\n",
    "print(f\"Current date: {current_date}\")\n",
    "print(f\"Current hour: {current_hour}\")\n",
    "\n",
    "# Define the range for the past 24 hours\n",
    "hours_to_predict = 24  # 24 hours\n",
    "window_size = 24 * 28  # 672 hours (28 days)\n",
    "start_hour = current_hour - timedelta(hours=(hours_to_predict - 1))  # Go back 23 hours from current_hour\n",
    "end_hour = current_hour  # Include the current hour\n",
    "\n",
    "# Adjust start_hour to ensure we have enough historical data for the window_size\n",
    "earliest_feature_hour = start_hour + timedelta(hours=window_size)\n",
    "if earliest_feature_hour > current_hour:\n",
    "    start_hour = current_hour - timedelta(hours=window_size + (hours_to_predict - 1))\n",
    "print(f\"Adjusted start_hour: {start_hour}\")\n",
    "print(f\"End hour (before adjustment): {end_hour}\")\n",
    "\n",
    "# Fetch data from citi_bike_hourly_feature_group\n",
    "# We need data for the past 24 hours plus the window size (28 days) to generate lagged features\n",
    "fetch_data_to = end_hour\n",
    "fetch_data_from = start_hour - timedelta(hours=window_size)  # Ensure enough history for lagging\n",
    "print(f\"Fetching data from {fetch_data_from} to {fetch_data_to}\")\n",
    "\n",
    "fg = feature_store.get_feature_group(\n",
    "    name=\"citi_bike_hourly_feature_group\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "query = fg.select_all()\n",
    "query = query.filter((fg.pickup_hour >= fetch_data_from) & (fg.pickup_hour <= fetch_data_to))\n",
    "ts_data = query.read()\n",
    "ts_data[\"pickup_hour\"] = pd.to_datetime(ts_data[\"pickup_hour\"]).dt.tz_localize(None)\n",
    "ts_data.sort_values([\"start_station_name\", \"pickup_hour\"]).reset_index(drop=True)\n",
    "ts_data.info()\n",
    "\n",
    "# Debugging: Print ts_data to inspect pickup_hour range\n",
    "print(\"\\nts_data (after filtering):\")\n",
    "print(\"Shape:\", ts_data.shape)\n",
    "print(\"pickup_hour range:\", ts_data[\"pickup_hour\"].min(), \"to\", ts_data[\"pickup_hour\"].max())\n",
    "print(ts_data)\n",
    "\n",
    "# Adjust end_hour to match the latest available data in ts_data\n",
    "end_hour = ts_data[\"pickup_hour\"].max()\n",
    "print(f\"Adjusted end_hour to match ts_data: {end_hour}\")\n",
    "\n",
    "# Transform the data into features using the updated transform_ts_data_info_features\n",
    "# Use step_size=1 to generate features for every hour\n",
    "features = transform_ts_data_info_features(ts_data, window_size=window_size, step_size=1)\n",
    "\n",
    "# Sort features by pickup_hour in descending order to ensure the most recent hour is selected\n",
    "features.sort_values(\"pickup_hour\", ascending=False, inplace=True)\n",
    "\n",
    "# Debugging: Print features to inspect pickup_hour range\n",
    "print(\"\\nfeatures:\")\n",
    "print(\"Shape:\", features.shape)\n",
    "print(\"pickup_hour range:\", features[\"pickup_hour\"].min(), \"to\", features[\"pickup_hour\"].max())\n",
    "print(features[[\"start_station_name\", \"pickup_hour\", \"rides_t-1\"]])\n",
    "\n",
    "# Define the model and corresponding feature group name\n",
    "model_name = \"baseline_previous_hour\"\n",
    "prediction_feature_group = \"predictions_model_baseline\"\n",
    "\n",
    "# Define the expected data type for this model's predicted_rides\n",
    "# baseline_previous_hour expects bigint (int64)\n",
    "model_predicted_rides_type = \"int64\"\n",
    "\n",
    "# Collect predictions for all hours\n",
    "all_predictions = []\n",
    "\n",
    "# Loop over the hours in the target range to generate predictions\n",
    "for hour_offset in range(hours_to_predict):\n",
    "    target_hour = (start_hour + timedelta(hours=hour_offset)).tz_localize(None)  # Make timezone-naive\n",
    "    if target_hour > end_hour:\n",
    "        print(f\"Target hour {target_hour} exceeds available data ({end_hour}). Skipping.\")\n",
    "        continue\n",
    "    print(f\"\\nGenerating predictions for hour: {target_hour}\")\n",
    "    \n",
    "    # Filter features for the target hour\n",
    "    features_for_hour = features[features[\"pickup_hour\"] == target_hour]\n",
    "    if features_for_hour.empty:\n",
    "        print(f\"No features found for {target_hour}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing model: {model_name} for {target_hour}\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model_from_registry(model_name=model_name)\n",
    "    \n",
    "    # Make predictions for this hour\n",
    "    predictions = get_model_predictions(model, features_for_hour, model_name=model_name)\n",
    "    predictions[\"pickup_hour\"] = target_hour\n",
    "    \n",
    "    # Debugging: Inspect features_for_hour for NaN or inf\n",
    "    print(f\"Features for {model_name} at {target_hour}:\")\n",
    "    print(features_for_hour)\n",
    "    print(\"Any NaN in features_for_hour:\", features_for_hour.isna().any().any())\n",
    "    print(\"Any inf in features_for_hour:\", np.isinf(features_for_hour.select_dtypes(include=[np.number])).any().any())\n",
    "    \n",
    "    # Debugging: Inspect raw predictions for NaN or inf\n",
    "    raw_predictions = model.predict(features_for_hour.drop(columns=[\"start_station_name\", \"pickup_hour\"]))\n",
    "    print(f\"Raw predictions for {model_name} at {target_hour}:\")\n",
    "    print(raw_predictions)\n",
    "    print(\"Any NaN in raw predictions:\", np.isnan(raw_predictions).any())\n",
    "    print(\"Any inf in raw predictions:\", np.isinf(raw_predictions).any())\n",
    "    \n",
    "    # Replace NaN or inf values in predicted_rides with 0\n",
    "    predictions[\"predicted_rides\"] = predictions[\"predicted_rides\"].replace([np.inf, -np.inf, np.nan], 0)\n",
    "    \n",
    "    # Convert predicted_rides to int64 to match feature group schema (bigint)\n",
    "    predictions[\"predicted_rides\"] = predictions[\"predicted_rides\"].astype(\"int64\")\n",
    "    \n",
    "    # Debugging: Print predictions to inspect data types\n",
    "    print(f\"Predictions for {model_name} at {target_hour}:\")\n",
    "    print(predictions)\n",
    "    print(\"Data types in predictions:\")\n",
    "    print(predictions.dtypes)\n",
    "    \n",
    "    # Append predictions to the list\n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "# Combine all predictions into a single DataFrame\n",
    "if all_predictions:\n",
    "    all_predictions_df = pd.concat(all_predictions, ignore_index=True)\n",
    "else:\n",
    "    raise ValueError(\"No predictions were generated for any hour.\")\n",
    "\n",
    "# Debugging: Print combined predictions\n",
    "print(\"\\nAll predictions combined:\")\n",
    "print(all_predictions_df)\n",
    "print(\"Data types in all_predictions_df:\")\n",
    "print(all_predictions_df.dtypes)\n",
    "\n",
    "# Create or retrieve the feature group for this model's predictions\n",
    "# Use version=1 since this matches the original working schema\n",
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=prediction_feature_group,\n",
    "    version=1,\n",
    "    description=f\"Predictions from {model_name} model\",\n",
    "    primary_key=[\"start_station_name\", \"pickup_hour\"],\n",
    "    event_time=\"pickup_hour\",\n",
    ")\n",
    "\n",
    "# Insert all predictions into the feature group in a single batch\n",
    "feature_group.insert(all_predictions_df, write_options={\"wait_for_job\": False})\n",
    "print(f\"Saved all predictions for {model_name} to feature group: {prediction_feature_group} (version 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9145dfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "2025-05-10 06:07:06,789 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:07:06,796 INFO: Initializing external client\n",
      "2025-05-10 06:07:06,796 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 06:07:07,477 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Current date: 2025-05-10 10:07:08.115339+00:00\n",
      "Current hour: 2025-05-10 10:00:00+00:00\n",
      "Adjusted start_hour: 2025-03-29 11:00:00+00:00\n",
      "End hour (before adjustment): 2025-05-10 10:00:00+00:00\n",
      "Fetching data from 2025-03-01 11:00:00+00:00 to 2025-05-10 10:00:00+00:00\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.56s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-11 08:00:00</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-11 09:00:00</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-11 10:00:00</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-04-11 11:00:00</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-04-11 12:00:00</td>\n",
       "      <td>11 Ave &amp; W 41 St</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4294</th>\n",
       "      <td>2025-05-10 02:00:00</td>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4295</th>\n",
       "      <td>2025-05-10 03:00:00</td>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4296</th>\n",
       "      <td>2025-05-10 04:00:00</td>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4297</th>\n",
       "      <td>2025-05-10 05:00:00</td>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4298</th>\n",
       "      <td>2025-05-10 06:00:00</td>\n",
       "      <td>W 31 St &amp; 7 Ave</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4299 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pickup_hour start_station_name  rides\n",
       "0    2025-04-11 08:00:00   11 Ave & W 41 St     16\n",
       "1    2025-04-11 09:00:00   11 Ave & W 41 St     16\n",
       "2    2025-04-11 10:00:00   11 Ave & W 41 St     14\n",
       "3    2025-04-11 11:00:00   11 Ave & W 41 St      7\n",
       "4    2025-04-11 12:00:00   11 Ave & W 41 St     14\n",
       "...                  ...                ...    ...\n",
       "4294 2025-05-10 02:00:00    W 31 St & 7 Ave      1\n",
       "4295 2025-05-10 03:00:00    W 31 St & 7 Ave      0\n",
       "4296 2025-05-10 04:00:00    W 31 St & 7 Ave      1\n",
       "4297 2025-05-10 05:00:00    W 31 St & 7 Ave      1\n",
       "4298 2025-05-10 06:00:00    W 31 St & 7 Ave     10\n",
       "\n",
       "[4299 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4299 entries, 0 to 4298\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   pickup_hour         4299 non-null   datetime64[us]\n",
      " 1   start_station_name  4299 non-null   object        \n",
      " 2   rides               4299 non-null   int32         \n",
      "dtypes: datetime64[us](1), int32(1), object(1)\n",
      "memory usage: 84.1+ KB\n",
      "\n",
      "ts_data (after filtering):\n",
      "Shape: (4299, 3)\n",
      "pickup_hour range: 2025-03-01 06:00:00 to 2025-05-10 06:00:00\n",
      "             pickup_hour start_station_name  rides\n",
      "0    2025-03-14 12:00:00    W 21 St & 6 Ave     23\n",
      "1    2025-03-12 17:00:00    W 21 St & 6 Ave     60\n",
      "2    2025-03-06 03:00:00    W 21 St & 6 Ave      0\n",
      "3    2025-03-27 11:00:00    W 21 St & 6 Ave     25\n",
      "4    2025-03-05 03:00:00    W 21 St & 6 Ave      0\n",
      "...                  ...                ...    ...\n",
      "4294 2025-04-27 06:00:00   11 Ave & W 41 St      1\n",
      "4295 2025-04-17 12:00:00    W 21 St & 6 Ave      8\n",
      "4296 2025-05-10 05:00:00    W 31 St & 7 Ave      1\n",
      "4297 2025-04-14 21:00:00    W 31 St & 7 Ave      9\n",
      "4298 2025-04-24 09:00:00    W 21 St & 6 Ave     17\n",
      "\n",
      "[4299 rows x 3 columns]\n",
      "Adjusted end_hour to match ts_data: 2025-05-10 06:00:00\n",
      "\n",
      "features:\n",
      "Shape: (939, 674)\n",
      "pickup_hour range: 2025-03-29 06:00:00 to 2025-05-10 06:00:00\n",
      "          start_station_name         pickup_hour  rides_t-1\n",
      "0            W 21 St & 6 Ave 2025-05-10 06:00:00          1\n",
      "916         11 Ave & W 41 St 2025-05-10 06:00:00          0\n",
      "893          W 31 St & 7 Ave 2025-05-10 06:00:00          1\n",
      "1            W 21 St & 6 Ave 2025-05-10 05:00:00          1\n",
      "894          W 31 St & 7 Ave 2025-05-10 05:00:00          1\n",
      "..                       ...                 ...        ...\n",
      "891  University Pl & E 14 St 2025-03-29 07:00:00          3\n",
      "825          8 Ave & W 31 St 2025-03-29 07:00:00          7\n",
      "760          W 21 St & 6 Ave 2025-03-29 06:00:00          1\n",
      "892  University Pl & E 14 St 2025-03-29 06:00:00          0\n",
      "826          8 Ave & W 31 St 2025-03-29 06:00:00          0\n",
      "\n",
      "[939 rows x 3 columns]\n",
      "\n",
      "Generating predictions for hour: 2025-03-29 11:00:00\n",
      "Processing model: baseline_previous_hour for 2025-03-29 11:00:00\n",
      "2025-05-10 06:07:10,225 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:07:10,234 INFO: Initializing external client\n",
      "2025-05-10 06:07:10,235 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 06:07:10,912 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Features for baseline_previous_hour at 2025-03-29 11:00:00:\n",
      "     rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
      "755           38           42           46           42           27   \n",
      "887           19           23           44           29           28   \n",
      "821           11            5           14           13           14   \n",
      "\n",
      "     rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
      "755           28           31           18           15           13  ...   \n",
      "887           27           17           18           13            4  ...   \n",
      "821           20           19           14            6            2  ...   \n",
      "\n",
      "     rides_t-8  rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  \\\n",
      "755          5          2          1          1          1         13   \n",
      "887          2          0          0          3          2          4   \n",
      "821          0          0          0          7          0          4   \n",
      "\n",
      "     rides_t-2  rides_t-1       start_station_name         pickup_hour  \n",
      "755         27         24          W 21 St & 6 Ave 2025-03-29 11:00:00  \n",
      "887         10         22  University Pl & E 14 St 2025-03-29 11:00:00  \n",
      "821          3         14          8 Ave & W 31 St 2025-03-29 11:00:00  \n",
      "\n",
      "[3 rows x 674 columns]\n",
      "Any NaN in features_for_hour: False\n",
      "Any inf in features_for_hour: False\n",
      "Raw predictions for baseline_previous_hour at 2025-03-29 11:00:00:\n",
      "755    24\n",
      "887    22\n",
      "821    14\n",
      "Name: rides_t-1, dtype: int64\n",
      "Any NaN in raw predictions: False\n",
      "Any inf in raw predictions: False\n",
      "Predictions for baseline_previous_hour at 2025-03-29 11:00:00:\n",
      "        start_station_name  predicted_rides         pickup_hour\n",
      "0          W 21 St & 6 Ave                0 2025-03-29 11:00:00\n",
      "1  University Pl & E 14 St                0 2025-03-29 11:00:00\n",
      "2          8 Ave & W 31 St                0 2025-03-29 11:00:00\n",
      "Data types in predictions:\n",
      "start_station_name            object\n",
      "predicted_rides                int64\n",
      "pickup_hour           datetime64[us]\n",
      "dtype: object\n",
      "\n",
      "Generating predictions for hour: 2025-03-29 12:00:00\n",
      "Processing model: baseline_previous_hour for 2025-03-29 12:00:00\n",
      "2025-05-10 06:07:12,685 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:07:12,690 INFO: Initializing external client\n",
      "2025-05-10 06:07:12,690 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 06:07:13,398 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Features for baseline_previous_hour at 2025-03-29 12:00:00:\n",
      "     rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
      "886           23           44           29           28           27   \n",
      "754           42           46           42           27           28   \n",
      "820            5           14           13           14           20   \n",
      "\n",
      "     rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
      "886           17           18           13            4            3  ...   \n",
      "754           31           18           15           13            5  ...   \n",
      "820           19           14            6            2            4  ...   \n",
      "\n",
      "     rides_t-8  rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  \\\n",
      "886          0          0          3          2          4         10   \n",
      "754          2          1          1          1         13         27   \n",
      "820          0          0          7          0          4          3   \n",
      "\n",
      "     rides_t-2  rides_t-1       start_station_name         pickup_hour  \n",
      "886         22         37  University Pl & E 14 St 2025-03-29 12:00:00  \n",
      "754         24         32          W 21 St & 6 Ave 2025-03-29 12:00:00  \n",
      "820         14         14          8 Ave & W 31 St 2025-03-29 12:00:00  \n",
      "\n",
      "[3 rows x 674 columns]\n",
      "Any NaN in features_for_hour: False\n",
      "Any inf in features_for_hour: False\n",
      "Raw predictions for baseline_previous_hour at 2025-03-29 12:00:00:\n",
      "886    37\n",
      "754    32\n",
      "820    14\n",
      "Name: rides_t-1, dtype: int64\n",
      "Any NaN in raw predictions: False\n",
      "Any inf in raw predictions: False\n",
      "Predictions for baseline_previous_hour at 2025-03-29 12:00:00:\n",
      "        start_station_name  predicted_rides         pickup_hour\n",
      "0  University Pl & E 14 St                0 2025-03-29 12:00:00\n",
      "1          W 21 St & 6 Ave                0 2025-03-29 12:00:00\n",
      "2          8 Ave & W 31 St                0 2025-03-29 12:00:00\n",
      "Data types in predictions:\n",
      "start_station_name            object\n",
      "predicted_rides                int64\n",
      "pickup_hour           datetime64[us]\n",
      "dtype: object\n",
      "\n",
      "Generating predictions for hour: 2025-03-29 13:00:00\n",
      "Processing model: baseline_previous_hour for 2025-03-29 13:00:00\n",
      "2025-05-10 06:07:15,140 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:07:15,146 INFO: Initializing external client\n",
      "2025-05-10 06:07:15,147 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 06:07:15,791 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Features for baseline_previous_hour at 2025-03-29 13:00:00:\n",
      "     rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
      "819           14           13           14           20           19   \n",
      "885           44           29           28           27           17   \n",
      "753           46           42           27           28           31   \n",
      "\n",
      "     rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
      "819           14            6            2            4            5  ...   \n",
      "885           18           13            4            3            5  ...   \n",
      "753           18           15           13            5            4  ...   \n",
      "\n",
      "     rides_t-8  rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  \\\n",
      "819          0          7          0          4          3         14   \n",
      "885          0          3          2          4         10         22   \n",
      "753          1          1          1         13         27         24   \n",
      "\n",
      "     rides_t-2  rides_t-1       start_station_name         pickup_hour  \n",
      "819         14         21          8 Ave & W 31 St 2025-03-29 13:00:00  \n",
      "885         37         31  University Pl & E 14 St 2025-03-29 13:00:00  \n",
      "753         32         37          W 21 St & 6 Ave 2025-03-29 13:00:00  \n",
      "\n",
      "[3 rows x 674 columns]\n",
      "Any NaN in features_for_hour: False\n",
      "Any inf in features_for_hour: False\n",
      "Raw predictions for baseline_previous_hour at 2025-03-29 13:00:00:\n",
      "819    21\n",
      "885    31\n",
      "753    37\n",
      "Name: rides_t-1, dtype: int64\n",
      "Any NaN in raw predictions: False\n",
      "Any inf in raw predictions: False\n",
      "Predictions for baseline_previous_hour at 2025-03-29 13:00:00:\n",
      "        start_station_name  predicted_rides         pickup_hour\n",
      "0          8 Ave & W 31 St                0 2025-03-29 13:00:00\n",
      "1  University Pl & E 14 St                0 2025-03-29 13:00:00\n",
      "2          W 21 St & 6 Ave                0 2025-03-29 13:00:00\n",
      "Data types in predictions:\n",
      "start_station_name            object\n",
      "predicted_rides                int64\n",
      "pickup_hour           datetime64[us]\n",
      "dtype: object\n",
      "\n",
      "Generating predictions for hour: 2025-03-29 14:00:00\n",
      "Processing model: baseline_previous_hour for 2025-03-29 14:00:00\n",
      "2025-05-10 06:07:17,311 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:07:17,318 INFO: Initializing external client\n",
      "2025-05-10 06:07:17,319 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 06:07:17,997 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Features for baseline_previous_hour at 2025-03-29 14:00:00:\n",
      "     rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
      "884           29           28           27           17           18   \n",
      "818           13           14           20           19           14   \n",
      "752           42           27           28           31           18   \n",
      "\n",
      "     rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
      "884           13            4            3            5            3  ...   \n",
      "818            6            2            4            5            0  ...   \n",
      "752           15           13            5            4            2  ...   \n",
      "\n",
      "     rides_t-8  rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  \\\n",
      "884          3          2          4         10         22         37   \n",
      "818          7          0          4          3         14         14   \n",
      "752          1          1         13         27         24         32   \n",
      "\n",
      "     rides_t-2  rides_t-1       start_station_name         pickup_hour  \n",
      "884         31         54  University Pl & E 14 St 2025-03-29 14:00:00  \n",
      "818         21         26          8 Ave & W 31 St 2025-03-29 14:00:00  \n",
      "752         37         47          W 21 St & 6 Ave 2025-03-29 14:00:00  \n",
      "\n",
      "[3 rows x 674 columns]\n",
      "Any NaN in features_for_hour: False\n",
      "Any inf in features_for_hour: False\n",
      "Raw predictions for baseline_previous_hour at 2025-03-29 14:00:00:\n",
      "884    54\n",
      "818    26\n",
      "752    47\n",
      "Name: rides_t-1, dtype: int64\n",
      "Any NaN in raw predictions: False\n",
      "Any inf in raw predictions: False\n",
      "Predictions for baseline_previous_hour at 2025-03-29 14:00:00:\n",
      "        start_station_name  predicted_rides         pickup_hour\n",
      "0  University Pl & E 14 St                0 2025-03-29 14:00:00\n",
      "1          8 Ave & W 31 St                0 2025-03-29 14:00:00\n",
      "2          W 21 St & 6 Ave                0 2025-03-29 14:00:00\n",
      "Data types in predictions:\n",
      "start_station_name            object\n",
      "predicted_rides                int64\n",
      "pickup_hour           datetime64[us]\n",
      "dtype: object\n",
      "\n",
      "Generating predictions for hour: 2025-03-29 15:00:00\n",
      "Processing model: baseline_previous_hour for 2025-03-29 15:00:00\n",
      "2025-05-10 06:07:19,790 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:07:19,796 INFO: Initializing external client\n",
      "2025-05-10 06:07:19,796 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 06:07:20,466 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Features for baseline_previous_hour at 2025-03-29 15:00:00:\n",
      "     rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
      "751           27           28           31           18           15   \n",
      "883           28           27           17           18           13   \n",
      "817           14           20           19           14            6   \n",
      "\n",
      "     rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
      "751           13            5            4            2            0  ...   \n",
      "883            4            3            5            3            2  ...   \n",
      "817            2            4            5            0            3  ...   \n",
      "\n",
      "     rides_t-8  rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  \\\n",
      "751          1         13         27         24         32         37   \n",
      "883          2          4         10         22         37         31   \n",
      "817          0          4          3         14         14         21   \n",
      "\n",
      "     rides_t-2  rides_t-1       start_station_name         pickup_hour  \n",
      "751         47         45          W 21 St & 6 Ave 2025-03-29 15:00:00  \n",
      "883         54         41  University Pl & E 14 St 2025-03-29 15:00:00  \n",
      "817         26         22          8 Ave & W 31 St 2025-03-29 15:00:00  \n",
      "\n",
      "[3 rows x 674 columns]\n",
      "Any NaN in features_for_hour: False\n",
      "Any inf in features_for_hour: False\n",
      "Raw predictions for baseline_previous_hour at 2025-03-29 15:00:00:\n",
      "751    45\n",
      "883    41\n",
      "817    22\n",
      "Name: rides_t-1, dtype: int64\n",
      "Any NaN in raw predictions: False\n",
      "Any inf in raw predictions: False\n",
      "Predictions for baseline_previous_hour at 2025-03-29 15:00:00:\n",
      "        start_station_name  predicted_rides         pickup_hour\n",
      "0          W 21 St & 6 Ave                0 2025-03-29 15:00:00\n",
      "1  University Pl & E 14 St                0 2025-03-29 15:00:00\n",
      "2          8 Ave & W 31 St                0 2025-03-29 15:00:00\n",
      "Data types in predictions:\n",
      "start_station_name            object\n",
      "predicted_rides                int64\n",
      "pickup_hour           datetime64[us]\n",
      "dtype: object\n",
      "\n",
      "Generating predictions for hour: 2025-03-29 16:00:00\n",
      "Processing model: baseline_previous_hour for 2025-03-29 16:00:00\n",
      "2025-05-10 06:07:22,110 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:07:22,116 INFO: Initializing external client\n",
      "2025-05-10 06:07:22,117 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 06:07:22,798 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Features for baseline_previous_hour at 2025-03-29 16:00:00:\n",
      "     rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
      "816           20           19           14            6            2   \n",
      "882           27           17           18           13            4   \n",
      "750           28           31           18           15           13   \n",
      "\n",
      "     rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
      "816            4            5            0            3            1  ...   \n",
      "882            3            5            3            2            3  ...   \n",
      "750            5            4            2            0            0  ...   \n",
      "\n",
      "     rides_t-8  rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  \\\n",
      "816          4          3         14         14         21         26   \n",
      "882          4         10         22         37         31         54   \n",
      "750         13         27         24         32         37         47   \n",
      "\n",
      "     rides_t-2  rides_t-1       start_station_name         pickup_hour  \n",
      "816         22         19          8 Ave & W 31 St 2025-03-29 16:00:00  \n",
      "882         41         44  University Pl & E 14 St 2025-03-29 16:00:00  \n",
      "750         45         30          W 21 St & 6 Ave 2025-03-29 16:00:00  \n",
      "\n",
      "[3 rows x 674 columns]\n",
      "Any NaN in features_for_hour: False\n",
      "Any inf in features_for_hour: False\n",
      "Raw predictions for baseline_previous_hour at 2025-03-29 16:00:00:\n",
      "816    19\n",
      "882    44\n",
      "750    30\n",
      "Name: rides_t-1, dtype: int64\n",
      "Any NaN in raw predictions: False\n",
      "Any inf in raw predictions: False\n",
      "Predictions for baseline_previous_hour at 2025-03-29 16:00:00:\n",
      "        start_station_name  predicted_rides         pickup_hour\n",
      "0          8 Ave & W 31 St                0 2025-03-29 16:00:00\n",
      "1  University Pl & E 14 St                0 2025-03-29 16:00:00\n",
      "2          W 21 St & 6 Ave                0 2025-03-29 16:00:00\n",
      "Data types in predictions:\n",
      "start_station_name            object\n",
      "predicted_rides                int64\n",
      "pickup_hour           datetime64[us]\n",
      "dtype: object\n",
      "\n",
      "Generating predictions for hour: 2025-03-29 17:00:00\n",
      "Processing model: baseline_previous_hour for 2025-03-29 17:00:00\n",
      "2025-05-10 06:07:24,315 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:07:24,319 INFO: Initializing external client\n",
      "2025-05-10 06:07:24,320 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 06:07:24,965 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Features for baseline_previous_hour at 2025-03-29 17:00:00:\n",
      "     rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
      "815           19           14            6            2            4   \n",
      "881           17           18           13            4            3   \n",
      "749           31           18           15           13            5   \n",
      "\n",
      "     rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
      "815            5            0            3            1            1  ...   \n",
      "881            5            3            2            3            2  ...   \n",
      "749            4            2            0            0            0  ...   \n",
      "\n",
      "     rides_t-8  rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  \\\n",
      "815          3         14         14         21         26         22   \n",
      "881         10         22         37         31         54         41   \n",
      "749         27         24         32         37         47         45   \n",
      "\n",
      "     rides_t-2  rides_t-1       start_station_name         pickup_hour  \n",
      "815         19         21          8 Ave & W 31 St 2025-03-29 17:00:00  \n",
      "881         44         31  University Pl & E 14 St 2025-03-29 17:00:00  \n",
      "749         30         27          W 21 St & 6 Ave 2025-03-29 17:00:00  \n",
      "\n",
      "[3 rows x 674 columns]\n",
      "Any NaN in features_for_hour: False\n",
      "Any inf in features_for_hour: False\n",
      "Raw predictions for baseline_previous_hour at 2025-03-29 17:00:00:\n",
      "815    21\n",
      "881    31\n",
      "749    27\n",
      "Name: rides_t-1, dtype: int64\n",
      "Any NaN in raw predictions: False\n",
      "Any inf in raw predictions: False\n",
      "Predictions for baseline_previous_hour at 2025-03-29 17:00:00:\n",
      "        start_station_name  predicted_rides         pickup_hour\n",
      "0          8 Ave & W 31 St                0 2025-03-29 17:00:00\n",
      "1  University Pl & E 14 St                0 2025-03-29 17:00:00\n",
      "2          W 21 St & 6 Ave                0 2025-03-29 17:00:00\n",
      "Data types in predictions:\n",
      "start_station_name            object\n",
      "predicted_rides                int64\n",
      "pickup_hour           datetime64[us]\n",
      "dtype: object\n",
      "\n",
      "Generating predictions for hour: 2025-03-29 18:00:00\n",
      "Processing model: baseline_previous_hour for 2025-03-29 18:00:00\n",
      "2025-05-10 06:07:26,455 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:07:26,465 INFO: Initializing external client\n",
      "2025-05-10 06:07:26,466 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 06:07:27,103 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Features for baseline_previous_hour at 2025-03-29 18:00:00:\n",
      "     rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
      "880           18           13            4            3            5   \n",
      "748           18           15           13            5            4   \n",
      "814           14            6            2            4            5   \n",
      "\n",
      "     rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
      "880            3            2            3            2            0  ...   \n",
      "748            2            0            0            0            2  ...   \n",
      "814            0            3            1            1            1  ...   \n",
      "\n",
      "     rides_t-8  rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  \\\n",
      "880         22         37         31         54         41         44   \n",
      "748         24         32         37         47         45         30   \n",
      "814         14         14         21         26         22         19   \n",
      "\n",
      "     rides_t-2  rides_t-1       start_station_name         pickup_hour  \n",
      "880         31         38  University Pl & E 14 St 2025-03-29 18:00:00  \n",
      "748         27         31          W 21 St & 6 Ave 2025-03-29 18:00:00  \n",
      "814         21         13          8 Ave & W 31 St 2025-03-29 18:00:00  \n",
      "\n",
      "[3 rows x 674 columns]\n",
      "Any NaN in features_for_hour: False\n",
      "Any inf in features_for_hour: False\n",
      "Raw predictions for baseline_previous_hour at 2025-03-29 18:00:00:\n",
      "880    38\n",
      "748    31\n",
      "814    13\n",
      "Name: rides_t-1, dtype: int64\n",
      "Any NaN in raw predictions: False\n",
      "Any inf in raw predictions: False\n",
      "Predictions for baseline_previous_hour at 2025-03-29 18:00:00:\n",
      "        start_station_name  predicted_rides         pickup_hour\n",
      "0  University Pl & E 14 St                0 2025-03-29 18:00:00\n",
      "1          W 21 St & 6 Ave                0 2025-03-29 18:00:00\n",
      "2          8 Ave & W 31 St                0 2025-03-29 18:00:00\n",
      "Data types in predictions:\n",
      "start_station_name            object\n",
      "predicted_rides                int64\n",
      "pickup_hour           datetime64[us]\n",
      "dtype: object\n",
      "\n",
      "Generating predictions for hour: 2025-03-29 19:00:00\n",
      "Processing model: baseline_previous_hour for 2025-03-29 19:00:00\n",
      "2025-05-10 06:07:28,599 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:07:28,605 INFO: Initializing external client\n",
      "2025-05-10 06:07:28,606 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 06:07:29,295 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Features for baseline_previous_hour at 2025-03-29 19:00:00:\n",
      "     rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
      "813            6            2            4            5            0   \n",
      "879           13            4            3            5            3   \n",
      "747           15           13            5            4            2   \n",
      "\n",
      "     rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
      "813            3            1            1            1            0  ...   \n",
      "879            2            3            2            0            0  ...   \n",
      "747            0            0            0            2            1  ...   \n",
      "\n",
      "     rides_t-8  rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  \\\n",
      "813         14         21         26         22         19         21   \n",
      "879         37         31         54         41         44         31   \n",
      "747         32         37         47         45         30         27   \n",
      "\n",
      "     rides_t-2  rides_t-1       start_station_name         pickup_hour  \n",
      "813         13         18          8 Ave & W 31 St 2025-03-29 19:00:00  \n",
      "879         38         20  University Pl & E 14 St 2025-03-29 19:00:00  \n",
      "747         31         23          W 21 St & 6 Ave 2025-03-29 19:00:00  \n",
      "\n",
      "[3 rows x 674 columns]\n",
      "Any NaN in features_for_hour: False\n",
      "Any inf in features_for_hour: False\n",
      "Raw predictions for baseline_previous_hour at 2025-03-29 19:00:00:\n",
      "813    18\n",
      "879    20\n",
      "747    23\n",
      "Name: rides_t-1, dtype: int64\n",
      "Any NaN in raw predictions: False\n",
      "Any inf in raw predictions: False\n",
      "Predictions for baseline_previous_hour at 2025-03-29 19:00:00:\n",
      "        start_station_name  predicted_rides         pickup_hour\n",
      "0          8 Ave & W 31 St                0 2025-03-29 19:00:00\n",
      "1  University Pl & E 14 St                0 2025-03-29 19:00:00\n",
      "2          W 21 St & 6 Ave                0 2025-03-29 19:00:00\n",
      "Data types in predictions:\n",
      "start_station_name            object\n",
      "predicted_rides                int64\n",
      "pickup_hour           datetime64[us]\n",
      "dtype: object\n",
      "\n",
      "Generating predictions for hour: 2025-03-29 20:00:00\n",
      "Processing model: baseline_previous_hour for 2025-03-29 20:00:00\n",
      "2025-05-10 06:07:30,869 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:07:30,873 INFO: Initializing external client\n",
      "2025-05-10 06:07:30,873 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 06:07:31,642 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Features for baseline_previous_hour at 2025-03-29 20:00:00:\n",
      "     rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
      "878            4            3            5            3            2   \n",
      "812            2            4            5            0            3   \n",
      "746           13            5            4            2            0   \n",
      "\n",
      "     rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
      "878            3            2            0            0            2  ...   \n",
      "812            1            1            1            0            0  ...   \n",
      "746            0            0            2            1            1  ...   \n",
      "\n",
      "     rides_t-8  rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  \\\n",
      "878         31         54         41         44         31         38   \n",
      "812         21         26         22         19         21         13   \n",
      "746         37         47         45         30         27         31   \n",
      "\n",
      "     rides_t-2  rides_t-1       start_station_name         pickup_hour  \n",
      "878         20         11  University Pl & E 14 St 2025-03-29 20:00:00  \n",
      "812         18         13          8 Ave & W 31 St 2025-03-29 20:00:00  \n",
      "746         23         22          W 21 St & 6 Ave 2025-03-29 20:00:00  \n",
      "\n",
      "[3 rows x 674 columns]\n",
      "Any NaN in features_for_hour: False\n",
      "Any inf in features_for_hour: False\n",
      "Raw predictions for baseline_previous_hour at 2025-03-29 20:00:00:\n",
      "878    11\n",
      "812    13\n",
      "746    22\n",
      "Name: rides_t-1, dtype: int64\n",
      "Any NaN in raw predictions: False\n",
      "Any inf in raw predictions: False\n",
      "Predictions for baseline_previous_hour at 2025-03-29 20:00:00:\n",
      "        start_station_name  predicted_rides         pickup_hour\n",
      "0  University Pl & E 14 St                0 2025-03-29 20:00:00\n",
      "1          8 Ave & W 31 St                0 2025-03-29 20:00:00\n",
      "2          W 21 St & 6 Ave                0 2025-03-29 20:00:00\n",
      "Data types in predictions:\n",
      "start_station_name            object\n",
      "predicted_rides                int64\n",
      "pickup_hour           datetime64[us]\n",
      "dtype: object\n",
      "\n",
      "Generating predictions for hour: 2025-03-29 21:00:00\n",
      "Processing model: baseline_previous_hour for 2025-03-29 21:00:00\n",
      "2025-05-10 06:07:33,179 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:07:33,186 INFO: Initializing external client\n",
      "2025-05-10 06:07:33,187 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 06:07:33,863 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Features for baseline_previous_hour at 2025-03-29 21:00:00:\n",
      "     rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
      "877            3            5            3            2            3   \n",
      "745            5            4            2            0            0   \n",
      "811            4            5            0            3            1   \n",
      "\n",
      "     rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
      "877            2            0            0            2            2  ...   \n",
      "745            0            2            1            1            1  ...   \n",
      "811            1            1            0            0            1  ...   \n",
      "\n",
      "     rides_t-8  rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  \\\n",
      "877         54         41         44         31         38         20   \n",
      "745         47         45         30         27         31         23   \n",
      "811         26         22         19         21         13         18   \n",
      "\n",
      "     rides_t-2  rides_t-1       start_station_name         pickup_hour  \n",
      "877         11         11  University Pl & E 14 St 2025-03-29 21:00:00  \n",
      "745         22         10          W 21 St & 6 Ave 2025-03-29 21:00:00  \n",
      "811         13          5          8 Ave & W 31 St 2025-03-29 21:00:00  \n",
      "\n",
      "[3 rows x 674 columns]\n",
      "Any NaN in features_for_hour: False\n",
      "Any inf in features_for_hour: False\n",
      "Raw predictions for baseline_previous_hour at 2025-03-29 21:00:00:\n",
      "877    11\n",
      "745    10\n",
      "811     5\n",
      "Name: rides_t-1, dtype: int64\n",
      "Any NaN in raw predictions: False\n",
      "Any inf in raw predictions: False\n",
      "Predictions for baseline_previous_hour at 2025-03-29 21:00:00:\n",
      "        start_station_name  predicted_rides         pickup_hour\n",
      "0  University Pl & E 14 St                0 2025-03-29 21:00:00\n",
      "1          W 21 St & 6 Ave                0 2025-03-29 21:00:00\n",
      "2          8 Ave & W 31 St                0 2025-03-29 21:00:00\n",
      "Data types in predictions:\n",
      "start_station_name            object\n",
      "predicted_rides                int64\n",
      "pickup_hour           datetime64[us]\n",
      "dtype: object\n",
      "\n",
      "Generating predictions for hour: 2025-03-29 22:00:00\n",
      "Processing model: baseline_previous_hour for 2025-03-29 22:00:00\n",
      "2025-05-10 06:07:35,430 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:07:35,435 INFO: Initializing external client\n",
      "2025-05-10 06:07:35,436 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 06:07:36,095 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Features for baseline_previous_hour at 2025-03-29 22:00:00:\n",
      "     rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
      "810            5            0            3            1            1   \n",
      "744            4            2            0            0            0   \n",
      "876            5            3            2            3            2   \n",
      "\n",
      "     rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
      "810            1            0            0            1            4  ...   \n",
      "744            2            1            1            1            2  ...   \n",
      "876            0            0            2            2            2  ...   \n",
      "\n",
      "     rides_t-8  rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  \\\n",
      "810         22         19         21         13         18         13   \n",
      "744         45         30         27         31         23         22   \n",
      "876         41         44         31         38         20         11   \n",
      "\n",
      "     rides_t-2  rides_t-1       start_station_name         pickup_hour  \n",
      "810          5          4          8 Ave & W 31 St 2025-03-29 22:00:00  \n",
      "744         10         10          W 21 St & 6 Ave 2025-03-29 22:00:00  \n",
      "876         11          7  University Pl & E 14 St 2025-03-29 22:00:00  \n",
      "\n",
      "[3 rows x 674 columns]\n",
      "Any NaN in features_for_hour: False\n",
      "Any inf in features_for_hour: False\n",
      "Raw predictions for baseline_previous_hour at 2025-03-29 22:00:00:\n",
      "810     4\n",
      "744    10\n",
      "876     7\n",
      "Name: rides_t-1, dtype: int64\n",
      "Any NaN in raw predictions: False\n",
      "Any inf in raw predictions: False\n",
      "Predictions for baseline_previous_hour at 2025-03-29 22:00:00:\n",
      "        start_station_name  predicted_rides         pickup_hour\n",
      "0          8 Ave & W 31 St                0 2025-03-29 22:00:00\n",
      "1          W 21 St & 6 Ave                0 2025-03-29 22:00:00\n",
      "2  University Pl & E 14 St                0 2025-03-29 22:00:00\n",
      "Data types in predictions:\n",
      "start_station_name            object\n",
      "predicted_rides                int64\n",
      "pickup_hour           datetime64[us]\n",
      "dtype: object\n",
      "\n",
      "Generating predictions for hour: 2025-03-29 23:00:00\n",
      "Processing model: baseline_previous_hour for 2025-03-29 23:00:00\n",
      "2025-05-10 06:07:37,590 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:07:37,594 INFO: Initializing external client\n",
      "2025-05-10 06:07:37,595 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 06:07:38,244 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Features for baseline_previous_hour at 2025-03-29 23:00:00:\n",
      "     rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
      "875            3            2            3            2            0   \n",
      "743            2            0            0            0            2   \n",
      "809            0            3            1            1            1   \n",
      "\n",
      "     rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
      "875            0            2            2            2            2  ...   \n",
      "743            1            1            1            2            7  ...   \n",
      "809            0            0            1            4            3  ...   \n",
      "\n",
      "     rides_t-8  rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  \\\n",
      "875         44         31         38         20         11         11   \n",
      "743         30         27         31         23         22         10   \n",
      "809         19         21         13         18         13          5   \n",
      "\n",
      "     rides_t-2  rides_t-1       start_station_name         pickup_hour  \n",
      "875          7          9  University Pl & E 14 St 2025-03-29 23:00:00  \n",
      "743         10          4          W 21 St & 6 Ave 2025-03-29 23:00:00  \n",
      "809          4         10          8 Ave & W 31 St 2025-03-29 23:00:00  \n",
      "\n",
      "[3 rows x 674 columns]\n",
      "Any NaN in features_for_hour: False\n",
      "Any inf in features_for_hour: False\n",
      "Raw predictions for baseline_previous_hour at 2025-03-29 23:00:00:\n",
      "875     9\n",
      "743     4\n",
      "809    10\n",
      "Name: rides_t-1, dtype: int64\n",
      "Any NaN in raw predictions: False\n",
      "Any inf in raw predictions: False\n",
      "Predictions for baseline_previous_hour at 2025-03-29 23:00:00:\n",
      "        start_station_name  predicted_rides         pickup_hour\n",
      "0  University Pl & E 14 St                0 2025-03-29 23:00:00\n",
      "1          W 21 St & 6 Ave                0 2025-03-29 23:00:00\n",
      "2          8 Ave & W 31 St                0 2025-03-29 23:00:00\n",
      "Data types in predictions:\n",
      "start_station_name            object\n",
      "predicted_rides                int64\n",
      "pickup_hour           datetime64[us]\n",
      "dtype: object\n",
      "\n",
      "Generating predictions for hour: 2025-03-30 00:00:00\n",
      "Processing model: baseline_previous_hour for 2025-03-30 00:00:00\n",
      "2025-05-10 06:07:39,668 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:07:39,674 INFO: Initializing external client\n",
      "2025-05-10 06:07:39,678 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 06:07:40,329 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Features for baseline_previous_hour at 2025-03-30 00:00:00:\n",
      "     rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
      "742            0            0            0            2            1   \n",
      "808            3            1            1            1            0   \n",
      "874            2            3            2            0            0   \n",
      "\n",
      "     rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
      "742            1            1            2            7           13  ...   \n",
      "808            0            1            4            3            2  ...   \n",
      "874            2            2            2            2            2  ...   \n",
      "\n",
      "     rides_t-8  rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  \\\n",
      "742         27         31         23         22         10         10   \n",
      "808         21         13         18         13          5          4   \n",
      "874         31         38         20         11         11          7   \n",
      "\n",
      "     rides_t-2  rides_t-1       start_station_name  pickup_hour  \n",
      "742          4          7          W 21 St & 6 Ave   2025-03-30  \n",
      "808         10          7          8 Ave & W 31 St   2025-03-30  \n",
      "874          9         17  University Pl & E 14 St   2025-03-30  \n",
      "\n",
      "[3 rows x 674 columns]\n",
      "Any NaN in features_for_hour: False\n",
      "Any inf in features_for_hour: False\n",
      "Raw predictions for baseline_previous_hour at 2025-03-30 00:00:00:\n",
      "742     7\n",
      "808     7\n",
      "874    17\n",
      "Name: rides_t-1, dtype: int64\n",
      "Any NaN in raw predictions: False\n",
      "Any inf in raw predictions: False\n",
      "Predictions for baseline_previous_hour at 2025-03-30 00:00:00:\n",
      "        start_station_name  predicted_rides pickup_hour\n",
      "0          W 21 St & 6 Ave                0  2025-03-30\n",
      "1          8 Ave & W 31 St                0  2025-03-30\n",
      "2  University Pl & E 14 St                0  2025-03-30\n",
      "Data types in predictions:\n",
      "start_station_name            object\n",
      "predicted_rides                int64\n",
      "pickup_hour           datetime64[us]\n",
      "dtype: object\n",
      "\n",
      "Generating predictions for hour: 2025-03-30 01:00:00\n",
      "Processing model: baseline_previous_hour for 2025-03-30 01:00:00\n",
      "2025-05-10 06:07:41,855 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 06:07:41,859 INFO: Initializing external client\n",
      "2025-05-10 06:07:41,860 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 116\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_hour\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model_from_registry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Make predictions for this hour\u001b[39;00m\n\u001b[0;32m    119\u001b[0m predictions \u001b[38;5;241m=\u001b[39m get_model_predictions(model, features_for_hour, model_name\u001b[38;5;241m=\u001b[39mmodel_name)\n",
      "File \u001b[1;32mc:\\Users\\singh\\Downloads\\CDS500_Applied_ML_DS\\Projects\\CDA500Final\\src\\inference.py:152\u001b[0m, in \u001b[0;36mload_model_from_registry\u001b[1;34m(model_name)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m project \u001b[38;5;241m=\u001b[39m \u001b[43mget_hopsworks_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m model_registry \u001b[38;5;241m=\u001b[39m project\u001b[38;5;241m.\u001b[39mget_model_registry()\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\singh\\Downloads\\CDS500_Applied_ML_DS\\Projects\\CDA500Final\\src\\inference.py:13\u001b[0m, in \u001b[0;36mget_hopsworks_project\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_hopsworks_project\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m hopsworks\u001b[38;5;241m.\u001b[39mproject\u001b[38;5;241m.\u001b[39mProject:\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhopsworks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHOPSWORKS_PROJECT_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHOPSWORKS_API_KEY\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\singh\\Downloads\\CDS500_Applied_ML_DS\\Projects\\CDA500Final\\CDA500PF2\\Lib\\site-packages\\hopsworks\\__init__.py:265\u001b[0m, in \u001b[0;36mlogin\u001b[1;34m(host, port, project, api_key_value, api_key_file, hostname_verification, trust_store_path, engine)\u001b[0m\n\u001b[0;32m    263\u001b[0m     _connected_project \u001b[38;5;241m=\u001b[39m _prompt_project(_hw_connection, project, is_app)\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _connected_project:\n\u001b[1;32m--> 265\u001b[0m         \u001b[43m_set_active_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_connected_project\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RestAPIError \u001b[38;5;28;01mas\u001b[39;00m hw_e:\n\u001b[0;32m    267\u001b[0m     logout()\n",
      "File \u001b[1;32mc:\\Users\\singh\\Downloads\\CDS500_Applied_ML_DS\\Projects\\CDA500Final\\CDA500PF2\\Lib\\site-packages\\hopsworks\\__init__.py:489\u001b[0m, in \u001b[0;36m_set_active_project\u001b[1;34m(project)\u001b[0m\n\u001b[0;32m    487\u001b[0m _client \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mget_instance()\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _client\u001b[38;5;241m.\u001b[39m_is_external():\n\u001b[1;32m--> 489\u001b[0m     \u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprovide_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\singh\\Downloads\\CDS500_Applied_ML_DS\\Projects\\CDA500Final\\CDA500PF2\\Lib\\site-packages\\hopsworks_common\\client\\external.py:99\u001b[0m, in \u001b[0;36mClient.provide_project\u001b[1;34m(self, project)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project_name \u001b[38;5;241m=\u001b[39m project\n\u001b[0;32m     97\u001b[0m _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProject name: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project_name)\n\u001b[1;32m---> 99\u001b[0m project_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_project_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(project_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprojectId\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    101\u001b[0m _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting Project ID: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_project_id)\n",
      "File \u001b[1;32mc:\\Users\\singh\\Downloads\\CDS500_Applied_ML_DS\\Projects\\CDA500Final\\CDA500PF2\\Lib\\site-packages\\hopsworks_common\\client\\external.py:300\u001b[0m, in \u001b[0;36mClient._get_project_info\u001b[1;34m(self, project_name)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Makes a REST call to hopsworks to get all metadata of a project for the provided project.\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \n\u001b[0;32m    294\u001b[0m \u001b[38;5;124;03m:param project_name: the name of the project\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;124;03m:rtype: dict\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    299\u001b[0m _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGetting project info for project: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, project_name)\n\u001b[1;32m--> 300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproject\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgetProjectInfo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\singh\\Downloads\\CDS500_Applied_ML_DS\\Projects\\CDA500Final\\CDA500PF2\\Lib\\site-packages\\hopsworks_common\\decorators.py:45\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[1;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inst\u001b[38;5;241m.\u001b[39m_connected:\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\singh\\Downloads\\CDS500_Applied_ML_DS\\Projects\\CDA500Final\\CDA500PF2\\Lib\\site-packages\\hopsworks_common\\client\\base.py:177\u001b[0m, in \u001b[0;36mClient._send_request\u001b[1;34m(self, method, path_params, query_params, headers, data, stream, files, with_base_path_params)\u001b[0m\n\u001b[0;32m    174\u001b[0m _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m hostname_verification:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(url, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify))\n\u001b[0;32m    176\u001b[0m prepped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mprepare_request(request)\n\u001b[1;32m--> 177\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_verify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mREST_ENDPOINT \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# refresh token and retry request - only on hopsworks\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_token_expired(\n\u001b[0;32m    182\u001b[0m         request, stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTOKEN_EXPIRED_RETRY_INTERVAL, \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    183\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\singh\\Downloads\\CDS500_Applied_ML_DS\\Projects\\CDA500Final\\CDA500PF2\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\singh\\Downloads\\CDS500_Applied_ML_DS\\Projects\\CDA500Final\\CDA500PF2\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\singh\\Downloads\\CDS500_Applied_ML_DS\\Projects\\CDA500Final\\CDA500PF2\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\singh\\Downloads\\CDS500_Applied_ML_DS\\Projects\\CDA500Final\\CDA500PF2\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\singh\\Downloads\\CDS500_Applied_ML_DS\\Projects\\CDA500Final\\CDA500PF2\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:708\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import src.config as config\n",
    "from src.inference import get_feature_store\n",
    "from src.data_utils import transform_ts_data_info_features\n",
    "from src.inference import load_batch_of_features_from_store\n",
    "from src.inference import load_model_from_registry\n",
    "from src.inference import get_model_predictions\n",
    "from src.inference import BaselineModelPreviousHour\n",
    "\n",
    "# Connect to Hopsworks and get the feature store\n",
    "feature_store = get_feature_store()\n",
    "\n",
    "# Get the current datetime\n",
    "current_date = pd.Timestamp.now(tz='Etc/UTC')\n",
    "current_hour = current_date.floor('h')\n",
    "print(f\"Current date: {current_date}\")\n",
    "print(f\"Current hour: {current_hour}\")\n",
    "\n",
    "# Define the range for the past 14 days (336 hours, including the current hour)\n",
    "hours_to_predict = 14 * 24  # 336 hours\n",
    "window_size = 24 * 28  # 672 hours (28 days)\n",
    "start_hour = current_hour - timedelta(hours=(hours_to_predict - 1))  # Go back 335 hours from current_hour\n",
    "end_hour = current_hour  # Include the current hour\n",
    "\n",
    "# Adjust start_hour to ensure we have enough historical data for the window_size\n",
    "earliest_feature_hour = start_hour + timedelta(hours=window_size)\n",
    "if earliest_feature_hour > current_hour:\n",
    "    start_hour = current_hour - timedelta(hours=window_size + (hours_to_predict - 1))\n",
    "print(f\"Adjusted start_hour: {start_hour}\")\n",
    "print(f\"End hour (before adjustment): {end_hour}\")\n",
    "\n",
    "# Fetch data from citi_bike_hourly_feature_group\n",
    "# We need data for the past 14 days plus the window size (28 days) to generate lagged features\n",
    "fetch_data_to = end_hour\n",
    "fetch_data_from = start_hour - timedelta(hours=window_size)  # Ensure enough history for lagging\n",
    "print(f\"Fetching data from {fetch_data_from} to {fetch_data_to}\")\n",
    "\n",
    "fg = feature_store.get_feature_group(\n",
    "    name=\"citi_bike_hourly_feature_group\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "query = fg.select_all()\n",
    "query = query.filter((fg.pickup_hour >= fetch_data_from) & (fg.pickup_hour <= fetch_data_to))\n",
    "ts_data = query.read()\n",
    "ts_data[\"pickup_hour\"] = pd.to_datetime(ts_data[\"pickup_hour\"]).dt.tz_localize(None)\n",
    "ts_data.sort_values([\"start_station_name\", \"pickup_hour\"]).reset_index(drop=True)\n",
    "ts_data.info()\n",
    "\n",
    "# Debugging: Print ts_data to inspect pickup_hour range\n",
    "print(\"\\nts_data (after filtering):\")\n",
    "print(\"Shape:\", ts_data.shape)\n",
    "print(\"pickup_hour range:\", ts_data[\"pickup_hour\"].min(), \"to\", ts_data[\"pickup_hour\"].max())\n",
    "print(ts_data)\n",
    "\n",
    "# Adjust end_hour to match the latest available data in ts_data\n",
    "end_hour = ts_data[\"pickup_hour\"].max()\n",
    "print(f\"Adjusted end_hour to match ts_data: {end_hour}\")\n",
    "\n",
    "# Transform the data into features using the updated transform_ts_data_info_features\n",
    "# Use step_size=1 to generate features for every hour\n",
    "features = transform_ts_data_info_features(ts_data, window_size=window_size, step_size=1)\n",
    "\n",
    "# Sort features by pickup_hour in descending order to ensure the most recent hour is selected\n",
    "features.sort_values(\"pickup_hour\", ascending=False, inplace=True)\n",
    "\n",
    "# Debugging: Print features to inspect pickup_hour range\n",
    "print(\"\\nfeatures:\")\n",
    "print(\"Shape:\", features.shape)\n",
    "print(\"pickup_hour range:\", features[\"pickup_hour\"].min(), \"to\", features[\"pickup_hour\"].max())\n",
    "print(features[[\"start_station_name\", \"pickup_hour\", \"rides_t-1\"]])\n",
    "\n",
    "# Define the model and corresponding feature group name\n",
    "model_name = \"baseline_previous_hour\"\n",
    "prediction_feature_group = \"predictions_model_baseline\"\n",
    "\n",
    "# Define the expected data type for this model's predicted_rides\n",
    "# baseline_previous_hour expects bigint (int64)\n",
    "model_predicted_rides_type = \"int64\"\n",
    "\n",
    "# Collect predictions for all hours\n",
    "all_predictions = []\n",
    "\n",
    "# Loop over the hours in the target range to generate predictions\n",
    "for hour_offset in range(hours_to_predict):\n",
    "    target_hour = (start_hour + timedelta(hours=hour_offset)).tz_localize(None)  # Make timezone-naive\n",
    "    if target_hour > end_hour:\n",
    "        print(f\"Target hour {target_hour} exceeds available data ({end_hour}). Skipping.\")\n",
    "        continue\n",
    "    print(f\"\\nGenerating predictions for hour: {target_hour}\")\n",
    "    \n",
    "    # Filter features for the target hour\n",
    "    features_for_hour = features[features[\"pickup_hour\"] == target_hour]\n",
    "    if features_for_hour.empty:\n",
    "        print(f\"No features found for {target_hour}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing model: {model_name} for {target_hour}\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model_from_registry(model_name=model_name)\n",
    "    \n",
    "    # Make predictions for this hour\n",
    "    predictions = get_model_predictions(model, features_for_hour, model_name=model_name)\n",
    "    predictions[\"pickup_hour\"] = target_hour\n",
    "    \n",
    "    # Debugging: Inspect features_for_hour for NaN or inf\n",
    "    print(f\"Features for {model_name} at {target_hour}:\")\n",
    "    print(features_for_hour)\n",
    "    print(\"Any NaN in features_for_hour:\", features_for_hour.isna().any().any())\n",
    "    print(\"Any inf in features_for_hour:\", np.isinf(features_for_hour.select_dtypes(include=[np.number])).any().any())\n",
    "    \n",
    "    # Debugging: Inspect raw predictions for NaN or inf\n",
    "    raw_predictions = model.predict(features_for_hour.drop(columns=[\"start_station_name\", \"pickup_hour\"]))\n",
    "    print(f\"Raw predictions for {model_name} at {target_hour}:\")\n",
    "    print(raw_predictions)\n",
    "    print(\"Any NaN in raw predictions:\", np.isnan(raw_predictions).any())\n",
    "    print(\"Any inf in raw predictions:\", np.isinf(raw_predictions).any())\n",
    "    \n",
    "    # Replace NaN or inf values in predicted_rides with 0\n",
    "    predictions[\"predicted_rides\"] = predictions[\"predicted_rides\"].replace([np.inf, -np.inf, np.nan], 0)\n",
    "    \n",
    "    # Convert predicted_rides to int64 to match feature group schema (bigint)\n",
    "    predictions[\"predicted_rides\"] = predictions[\"predicted_rides\"].astype(\"int64\")\n",
    "    \n",
    "    # Debugging: Print predictions to inspect data types\n",
    "    print(f\"Predictions for {model_name} at {target_hour}:\")\n",
    "    print(predictions)\n",
    "    print(\"Data types in predictions:\")\n",
    "    print(predictions.dtypes)\n",
    "    \n",
    "    # Append predictions to the list\n",
    "    all_predictions.append(predictions)\n",
    "\n",
    "# Combine all predictions into a single DataFrame\n",
    "if all_predictions:\n",
    "    all_predictions_df = pd.concat(all_predictions, ignore_index=True)\n",
    "else:\n",
    "    raise ValueError(\"No predictions were generated for any hour.\")\n",
    "\n",
    "# Debugging: Print combined predictions\n",
    "print(\"\\nAll predictions combined:\")\n",
    "print(all_predictions_df)\n",
    "print(\"Data types in all_predictions_df:\")\n",
    "print(all_predictions_df.dtypes)\n",
    "\n",
    "# Create or retrieve the feature group for this model's predictions\n",
    "# Use version=1 since this matches the original working schema\n",
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=prediction_feature_group,\n",
    "    version=1,\n",
    "    description=f\"Predictions from {model_name} model\",\n",
    "    primary_key=[\"start_station_name\", \"pickup_hour\"],\n",
    "    event_time=\"pickup_hour\",\n",
    ")\n",
    "\n",
    "# Insert all predictions into the feature group in a single batch\n",
    "feature_group.insert(all_predictions_df, write_options={\"wait_for_job\": False})\n",
    "print(f\"Saved all predictions for {model_name} to feature group: {prediction_feature_group} (version 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae479cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import src.config as config\n",
    "from src.inference import get_feature_store\n",
    "from src.data_utils import transform_ts_data_info_features\n",
    "from src.inference import load_batch_of_features_from_store\n",
    "from src.inference import load_model_from_registry\n",
    "from src.inference import get_model_predictions\n",
    "from src.inference import BaselineModelPreviousHour\n",
    "\n",
    "# Connect to Hopsworks and get the feature store\n",
    "feature_store = get_feature_store()\n",
    "\n",
    "# Retrieve the feature group with recent data\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=\"recent_time_series_hourly_feature_group\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Create or retrieve the feature view for recent data\n",
    "try:\n",
    "    feature_store.create_feature_view(\n",
    "        name=\"citi_bike_recent_hourly_feature_view\",\n",
    "        version=1,\n",
    "        query=feature_group.select_all(),\n",
    "    )\n",
    "    print(f\"Feature view 'citi_bike_recent_hourly_feature_view' (version 1) created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating feature view: {e}\")\n",
    "\n",
    "feature_view = feature_store.get_feature_view(\n",
    "    name=\"citi_bike_recent_hourly_feature_view\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Get the current datetime\n",
    "current_date = pd.Timestamp.now(tz='Etc/UTC')\n",
    "\n",
    "# Read time-series data from the feature store\n",
    "fetch_data_to = current_date - timedelta(hours=1)\n",
    "fetch_data_from = current_date - timedelta(days=1*29)\n",
    "print(f\"Fetching data from {fetch_data_from} to {fetch_data_to}\")\n",
    "\n",
    "ts_data = feature_view.get_batch_data(\n",
    "    start_time=(fetch_data_from - timedelta(days=1)),\n",
    "    end_time=(fetch_data_to + timedelta(days=1)),\n",
    ")\n",
    "ts_data = ts_data[ts_data.pickup_hour.between(fetch_data_from, fetch_data_to)]\n",
    "ts_data.sort_values([\"start_station_name\", \"pickup_hour\"]).reset_index(drop=True)\n",
    "ts_data.info()\n",
    "\n",
    "ts_data[\"pickup_hour\"] = ts_data[\"pickup_hour\"].dt.tz_localize(None)\n",
    "ts_data.info()\n",
    "\n",
    "# Transform the data into features\n",
    "features = transform_ts_data_info_features(ts_data, window_size=24*28, step_size=23)\n",
    "\n",
    "# Filter features for the most recent hour (next hour prediction)\n",
    "features_next_hour = features.groupby(\"start_station_name\").last().reset_index()\n",
    "next_hour = features_next_hour[\"pickup_hour\"].max()\n",
    "print(f\"Making predictions for the next hour: {next_hour}\")\n",
    "\n",
    "# Define the list of models\n",
    "models = [\n",
    "    \"baseline_previous_hour\",\n",
    "    \"lightgbm_28days_lags\",\n",
    "    \"lightgbm_top10_features\",\n",
    "    \"gradient_boosting_temporal_features\",\n",
    "    \"lightgbm_enhanced_lags_cyclic_temporal_interactions\"\n",
    "]\n",
    "\n",
    "# Map models to shorter feature group names\n",
    "prediction_feature_groups = {\n",
    "    \"baseline_previous_hour\": \"predictions_model_baseline\",\n",
    "    \"lightgbm_28days_lags\": \"predictions_model_lgbm_28days\",\n",
    "    \"lightgbm_top10_features\": \"predictions_model_lgbm_top10\",\n",
    "    \"gradient_boosting_temporal_features\": \"predictions_model_gbt\",\n",
    "    \"lightgbm_enhanced_lags_cyclic_temporal_interactions\": \"predictions_model_lgbm_enhanced\"\n",
    "}\n",
    "\n",
    "# Make predictions with each model and save to separate feature groups\n",
    "for model_name in models:\n",
    "    print(f\"\\nProcessing model: {model_name}\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model_from_registry(model_name=model_name)\n",
    "    \n",
    "    # Make predictions for the next hour\n",
    "    predictions = get_model_predictions(model, features_next_hour, model_name=model_name)\n",
    "    predictions[\"pickup_hour\"] = current_date.ceil('h')\n",
    "    predictions\n",
    "    \n",
    "    # Create or retrieve the feature group for this model's predictions\n",
    "    feature_group = feature_store.get_or_create_feature_group(\n",
    "        name=prediction_feature_groups[model_name],\n",
    "        version=1,\n",
    "        description=f\"Predictions from {model_name} model\",\n",
    "        primary_key=[\"start_station_name\", \"pickup_hour\"],\n",
    "        event_time=\"pickup_hour\",\n",
    "    )\n",
    "    \n",
    "    # Insert the predictions into the feature group\n",
    "    feature_group.insert(predictions, write_options={\"wait_for_job\": False})\n",
    "    print(f\"Saved predictions to feature group: {prediction_feature_groups[model_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1280151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import src.config as config\n",
    "from src.inference import get_feature_store\n",
    "from src.data_utils import transform_ts_data_info_features\n",
    "from src.inference import load_batch_of_features_from_store\n",
    "from src.inference import load_model_from_registry\n",
    "from src.inference import get_model_predictions\n",
    "from src.inference import BaselineModelPreviousHour\n",
    "\n",
    "# Connect to Hopsworks and get the feature store\n",
    "feature_store = get_feature_store()\n",
    "\n",
    "# Retrieve the feature group with recent data\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=\"recent_time_series_hourly_feature_group\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Create or retrieve the feature view for recent data\n",
    "try:\n",
    "    feature_store.create_feature_view(\n",
    "        name=\"citi_bike_recent_hourly_feature_view\",\n",
    "        version=1,\n",
    "        query=feature_group.select_all(),\n",
    "    )\n",
    "    print(f\"Feature view 'citi_bike_recent_hourly_feature_view' (version 1) created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating feature view: {e}\")\n",
    "\n",
    "feature_view = feature_store.get_feature_view(\n",
    "    name=\"citi_bike_recent_hourly_feature_view\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Get the current datetime\n",
    "current_date = pd.Timestamp.now(tz='Etc/UTC')\n",
    "\n",
    "# Read time-series data from the feature store\n",
    "fetch_data_to = current_date - timedelta(hours=1)\n",
    "fetch_data_from = current_date - timedelta(days=1*29)\n",
    "print(f\"Fetching data from {fetch_data_from} to {fetch_data_to}\")\n",
    "\n",
    "ts_data = feature_view.get_batch_data(\n",
    "    start_time=(fetch_data_from - timedelta(days=1)),\n",
    "    end_time=(fetch_data_to + timedelta(days=1)),\n",
    ")\n",
    "ts_data = ts_data[ts_data.pickup_hour.between(fetch_data_from, fetch_data_to)]\n",
    "ts_data.sort_values([\"start_station_name\", \"pickup_hour\"]).reset_index(drop=True)\n",
    "ts_data.info()\n",
    "\n",
    "ts_data[\"pickup_hour\"] = ts_data[\"pickup_hour\"].dt.tz_localize(None)\n",
    "ts_data.info()\n",
    "\n",
    "# Transform the data into features\n",
    "features = transform_ts_data_info_features(ts_data, window_size=24*28, step_size=23)\n",
    "\n",
    "# Filter features for the most recent hour (next hour prediction)\n",
    "features_next_hour = features.groupby(\"start_station_name\").last().reset_index()\n",
    "recent_hour = features_next_hour[\"pickup_hour\"].max()\n",
    "print(f\"Making predictions for the most recent hour: {recent_hour}\")\n",
    "\n",
    "# Define the list of models and corresponding feature group names\n",
    "models = [\n",
    "    \"baseline_previous_hour\",\n",
    "    \"lightgbm_28days_lags\",\n",
    "    \"lightgbm_top10_features\",\n",
    "    \"gradient_boosting_temporal_features\",\n",
    "    \"lightgbm_enhanced_lags_cyclic_temporal_interactions\"\n",
    "]\n",
    "\n",
    "prediction_feature_groups = {\n",
    "    \"baseline_previous_hour\": \"predictions_model_baseline\",\n",
    "    \"lightgbm_28days_lags\": \"predictions_model_lgbm_28days\",\n",
    "    \"lightgbm_top10_features\": \"predictions_model_lgbm_top10\",\n",
    "    \"gradient_boosting_temporal_features\": \"predictions_model_gbt\",\n",
    "    \"lightgbm_enhanced_lags_cyclic_temporal_interactions\": \"predictions_model_lgbm_enhanced\"\n",
    "}\n",
    "\n",
    "# Make predictions with each model and save to separate feature groups\n",
    "for model_name in models:\n",
    "    print(f\"\\nProcessing model: {model_name}\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model_from_registry(model_name=model_name)\n",
    "    \n",
    "    # Make predictions for the most recent hour\n",
    "    predictions = get_model_predictions(model, features_next_hour, model_name=model_name)\n",
    "    predictions[\"pickup_hour\"] = recent_hour  # Use the most recent actual hour\n",
    "    predictions\n",
    "    \n",
    "    # Create or retrieve the feature group for this model's predictions\n",
    "    feature_group = feature_store.get_or_create_feature_group(\n",
    "        name=prediction_feature_groups[model_name],\n",
    "        version=1,\n",
    "        description=f\"Predictions from {model_name} model\",\n",
    "        primary_key=[\"start_station_name\", \"pickup_hour\"],\n",
    "        event_time=\"pickup_hour\",\n",
    "    )\n",
    "    \n",
    "    # Insert the predictions into the feature group\n",
    "    feature_group.insert(predictions, write_options={\"wait_for_job\": False})\n",
    "    print(f\"Saved predictions to feature group: {prediction_feature_groups[model_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ee1085",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import src.config as config\n",
    "from src.inference import get_feature_store\n",
    "from src.data_utils import transform_ts_data_info_features\n",
    "from src.inference import load_batch_of_features_from_store\n",
    "from src.inference import load_model_from_registry\n",
    "from src.inference import get_model_predictions\n",
    "from src.inference import BaselineModelPreviousHour\n",
    "\n",
    "# Connect to Hopsworks and get the feature store\n",
    "feature_store = get_feature_store()\n",
    "\n",
    "# Retrieve the feature group with recent data\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=\"recent_time_series_hourly_feature_group\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Create or retrieve the feature view for recent data\n",
    "try:\n",
    "    feature_store.create_feature_view(\n",
    "        name=\"citi_bike_recent_hourly_feature_view\",\n",
    "        version=1,\n",
    "        query=feature_group.select_all(),\n",
    "    )\n",
    "    print(f\"Feature view 'citi_bike_recent_hourly_feature_view' (version 1) created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating feature view: {e}\")\n",
    "\n",
    "feature_view = feature_store.get_feature_view(\n",
    "    name=\"citi_bike_recent_hourly_feature_view\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Get the current datetime\n",
    "current_date = pd.Timestamp.now(tz='Etc/UTC')\n",
    "print(f\"Current date: {current_date}\")\n",
    "\n",
    "# Read time-series data from the feature store\n",
    "fetch_data_to = current_date.floor('h')  # Include the current hour\n",
    "fetch_data_from = current_date - timedelta(days=1*29)\n",
    "print(f\"Fetching data from {fetch_data_from} to {fetch_data_to}\")\n",
    "\n",
    "ts_data = feature_view.get_batch_data(\n",
    "    start_time=(fetch_data_from - timedelta(days=1)),\n",
    "    end_time=(fetch_data_to + timedelta(days=1)),\n",
    ")\n",
    "ts_data = ts_data[ts_data.pickup_hour.between(fetch_data_from, fetch_data_to)]\n",
    "ts_data.sort_values([\"start_station_name\", \"pickup_hour\"]).reset_index(drop=True)\n",
    "ts_data.info()\n",
    "\n",
    "ts_data[\"pickup_hour\"] = ts_data[\"pickup_hour\"].dt.tz_localize(None)\n",
    "ts_data.info()\n",
    "\n",
    "# Debugging: Print ts_data to inspect pickup_hour range\n",
    "print(\"\\nts_data (after filtering):\")\n",
    "print(\"Shape:\", ts_data.shape)\n",
    "print(\"pickup_hour range:\", ts_data[\"pickup_hour\"].min(), \"to\", ts_data[\"pickup_hour\"].max())\n",
    "print(ts_data)\n",
    "\n",
    "# Transform the data into features\n",
    "features = transform_ts_data_info_features(ts_data, window_size=24*28, step_size=23)\n",
    "\n",
    "# Filter features for the most recent hour\n",
    "features_next_hour = features.groupby(\"start_station_name\").last().reset_index()\n",
    "recent_hour = features_next_hour[\"pickup_hour\"].max()\n",
    "print(f\"\\nMost recent hour in features_next_hour: {recent_hour}\")\n",
    "\n",
    "# Debugging: Print features_next_hour\n",
    "print(\"\\nfeatures_next_hour:\")\n",
    "print(\"Shape:\", features_next_hour.shape)\n",
    "print(features_next_hour)\n",
    "\n",
    "# Define the list of models and corresponding feature group names\n",
    "models = [\n",
    "    \"baseline_previous_hour\",\n",
    "    \"lightgbm_28days_lags\",\n",
    "    \"lightgbm_top10_features\",\n",
    "    \"gradient_boosting_temporal_features\",\n",
    "    \"lightgbm_enhanced_lags_cyclic_temporal_interactions\"\n",
    "]\n",
    "\n",
    "prediction_feature_groups = {\n",
    "    \"baseline_previous_hour\": \"predictions_model_baseline\",\n",
    "    \"lightgbm_28days_lags\": \"predictions_model_lgbm_28days\",\n",
    "    \"lightgbm_top10_features\": \"predictions_model_lgbm_top10\",\n",
    "    \"gradient_boosting_temporal_features\": \"predictions_model_gbt\",\n",
    "    \"lightgbm_enhanced_lags_cyclic_temporal_interactions\": \"predictions_model_lgbm_enhanced\"\n",
    "}\n",
    "\n",
    "# Make predictions with each model and save to separate feature groups\n",
    "for model_name in models:\n",
    "    print(f\"\\nProcessing model: {model_name}\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model_from_registry(model_name=model_name)\n",
    "    \n",
    "    # Make predictions for the most recent hour\n",
    "    predictions = get_model_predictions(model, features_next_hour, model_name=model_name)\n",
    "    predictions[\"pickup_hour\"] = recent_hour  # Use the most recent actual hour\n",
    "    predictions\n",
    "    \n",
    "    # Create or retrieve the feature group for this model's predictions\n",
    "    feature_group = feature_store.get_or_create_feature_group(\n",
    "        name=prediction_feature_groups[model_name],\n",
    "        version=1,\n",
    "        description=f\"Predictions from {model_name} model\",\n",
    "        primary_key=[\"start_station_name\", \"pickup_hour\"],\n",
    "        event_time=\"pickup_hour\",\n",
    "    )\n",
    "    \n",
    "    # Insert the predictions into the feature group\n",
    "    feature_group.insert(predictions, write_options={\"wait_for_job\": False})\n",
    "    print(f\"Saved predictions to feature group: {prediction_feature_groups[model_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a04acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import src.config as config\n",
    "from src.inference import get_feature_store\n",
    "from src.data_utils import transform_ts_data_info_features\n",
    "from src.inference import load_batch_of_features_from_store\n",
    "from src.inference import load_model_from_registry\n",
    "from src.inference import get_model_predictions\n",
    "from src.inference import BaselineModelPreviousHour\n",
    "\n",
    "# Connect to Hopsworks and get the feature store\n",
    "feature_store = get_feature_store()\n",
    "\n",
    "# Retrieve the feature group with recent data\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=\"recent_time_series_hourly_feature_group\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Create or retrieve the feature view for recent data\n",
    "try:\n",
    "    feature_store.create_feature_view(\n",
    "        name=\"citi_bike_recent_hourly_feature_view\",\n",
    "        version=1,\n",
    "        query=feature_group.select_all(),\n",
    "    )\n",
    "    print(f\"Feature view 'citi_bike_recent_hourly_feature_view' (version 1) created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating feature view: {e}\")\n",
    "\n",
    "feature_view = feature_store.get_feature_view(\n",
    "    name=\"citi_bike_recent_hourly_feature_view\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Get the current datetime\n",
    "current_date = pd.Timestamp.now(tz='Etc/UTC')\n",
    "print(f\"Current date: {current_date}\")\n",
    "\n",
    "# Read time-series data from the feature store\n",
    "fetch_data_to = current_date.floor('h')  # Include the current hour\n",
    "fetch_data_from = current_date - timedelta(days=1*29)\n",
    "print(f\"Fetching data from {fetch_data_from} to {fetch_data_to}\")\n",
    "\n",
    "ts_data = feature_view.get_batch_data(\n",
    "    start_time=(fetch_data_from - timedelta(days=1)),\n",
    "    end_time=(fetch_data_to + timedelta(days=1)),\n",
    ")\n",
    "ts_data = ts_data[ts_data.pickup_hour.between(fetch_data_from, fetch_data_to)]\n",
    "ts_data.sort_values([\"start_station_name\", \"pickup_hour\"]).reset_index(drop=True)\n",
    "ts_data.info()\n",
    "\n",
    "ts_data[\"pickup_hour\"] = ts_data[\"pickup_hour\"].dt.tz_localize(None)\n",
    "ts_data.info()\n",
    "\n",
    "# Debugging: Print ts_data to inspect pickup_hour range\n",
    "print(\"\\nts_data (after filtering):\")\n",
    "print(\"Shape:\", ts_data.shape)\n",
    "print(\"pickup_hour range:\", ts_data[\"pickup_hour\"].min(), \"to\", ts_data[\"pickup_hour\"].max())\n",
    "print(ts_data)\n",
    "\n",
    "# Transform the data into features\n",
    "features = transform_ts_data_info_features(ts_data, window_size=24*28, step_size=23)\n",
    "\n",
    "# Sort features by pickup_hour in descending order to ensure the most recent hour is selected\n",
    "features.sort_values(\"pickup_hour\", ascending=False, inplace=True)\n",
    "\n",
    "# Filter features for the most recent hour\n",
    "features_next_hour = features.groupby(\"start_station_name\").first().reset_index()\n",
    "recent_hour = features_next_hour[\"pickup_hour\"].max()\n",
    "print(f\"\\nMost recent hour in features_next_hour: {recent_hour}\")\n",
    "\n",
    "# Debugging: Print features_next_hour\n",
    "print(\"\\nfeatures_next_hour:\")\n",
    "print(\"Shape:\", features_next_hour.shape)\n",
    "print(features_next_hour)\n",
    "\n",
    "# Define the list of models and corresponding feature group names\n",
    "models = [\n",
    "    \"baseline_previous_hour\",\n",
    "    \"lightgbm_28days_lags\",\n",
    "    \"lightgbm_top10_features\",\n",
    "    \"gradient_boosting_temporal_features\",\n",
    "    \"lightgbm_enhanced_lags_cyclic_temporal_interactions\"\n",
    "]\n",
    "\n",
    "prediction_feature_groups = {\n",
    "    \"baseline_previous_hour\": \"predictions_model_baseline\",\n",
    "    \"lightgbm_28days_lags\": \"predictions_model_lgbm_28days\",\n",
    "    \"lightgbm_top10_features\": \"predictions_model_lgbm_top10\",\n",
    "    \"gradient_boosting_temporal_features\": \"predictions_model_gbt\",\n",
    "    \"lightgbm_enhanced_lags_cyclic_temporal_interactions\": \"predictions_model_lgbm_enhanced\"\n",
    "}\n",
    "\n",
    "# Make predictions with each model and save to separate feature groups\n",
    "for model_name in models:\n",
    "    print(f\"\\nProcessing model: {model_name}\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model_from_registry(model_name=model_name)\n",
    "    \n",
    "    # Make predictions for the most recent hour\n",
    "    predictions = get_model_predictions(model, features_next_hour, model_name=model_name)\n",
    "    predictions[\"pickup_hour\"] = recent_hour  # Use the most recent actual hour\n",
    "    predictions\n",
    "    \n",
    "    # Create or retrieve the feature group for this model's predictions\n",
    "    feature_group = feature_store.get_or_create_feature_group(\n",
    "        name=prediction_feature_groups[model_name],\n",
    "        version=1,\n",
    "        description=f\"Predictions from {model_name} model\",\n",
    "        primary_key=[\"start_station_name\", \"pickup_hour\"],\n",
    "        event_time=\"pickup_hour\",\n",
    "    )\n",
    "    \n",
    "    # Insert the predictions into the feature group\n",
    "    feature_group.insert(predictions, write_options={\"wait_for_job\": False})\n",
    "    print(f\"Saved predictions to feature group: {prediction_feature_groups[model_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd3d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import src.config as config\n",
    "from src.inference import get_feature_store\n",
    "from src.data_utils import transform_ts_data_info_features\n",
    "from src.inference import load_batch_of_features_from_store\n",
    "from src.inference import load_model_from_registry\n",
    "from src.inference import get_model_predictions\n",
    "from src.inference import BaselineModelPreviousHour\n",
    "\n",
    "# Connect to Hopsworks and get the feature store\n",
    "feature_store = get_feature_store()\n",
    "\n",
    "# Retrieve the feature group with recent data\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=\"recent_time_series_hourly_feature_group\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Create or retrieve the feature view for recent data\n",
    "try:\n",
    "    feature_store.create_feature_view(\n",
    "        name=\"citi_bike_recent_hourly_feature_view\",\n",
    "        version=1,\n",
    "        query=feature_group.select_all(),\n",
    "    )\n",
    "    print(f\"Feature view 'citi_bike_recent_hourly_feature_view' (version 1) created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating feature view: {e}\")\n",
    "\n",
    "feature_view = feature_store.get_feature_view(\n",
    "    name=\"citi_bike_recent_hourly_feature_view\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Get the current datetime\n",
    "current_date = pd.Timestamp.now(tz='Etc/UTC')\n",
    "print(f\"Current date: {current_date}\")\n",
    "\n",
    "# Read time-series data from the feature store\n",
    "fetch_data_to = current_date.floor('h')  # Include the current hour\n",
    "fetch_data_from = current_date - timedelta(days=1*29)\n",
    "print(f\"Fetching data from {fetch_data_from} to {fetch_data_to}\")\n",
    "\n",
    "ts_data = feature_view.get_batch_data(\n",
    "    start_time=(fetch_data_from - timedelta(days=1)),\n",
    "    end_time=(fetch_data_to + timedelta(days=1)),\n",
    ")\n",
    "ts_data = ts_data[ts_data.pickup_hour.between(fetch_data_from, fetch_data_to)]\n",
    "ts_data.sort_values([\"start_station_name\", \"pickup_hour\"]).reset_index(drop=True)\n",
    "ts_data.info()\n",
    "\n",
    "ts_data[\"pickup_hour\"] = ts_data[\"pickup_hour\"].dt.tz_localize(None)\n",
    "ts_data.info()\n",
    "\n",
    "# Debugging: Print ts_data to inspect pickup_hour range\n",
    "print(\"\\nts_data (after filtering):\")\n",
    "print(\"Shape:\", ts_data.shape)\n",
    "print(\"pickup_hour range:\", ts_data[\"pickup_hour\"].min(), \"to\", ts_data[\"pickup_hour\"].max())\n",
    "print(ts_data)\n",
    "\n",
    "# Transform the data into features\n",
    "features = transform_ts_data_info_features(ts_data, window_size=24*28, step_size=23)\n",
    "\n",
    "# Debugging: Inspect features before sorting\n",
    "print(\"\\nfeatures (before sorting):\")\n",
    "print(\"Shape:\", features.shape)\n",
    "print(\"pickup_hour range:\", features[\"pickup_hour\"].min(), \"to\", features[\"pickup_hour\"].max())\n",
    "print(features[[\"start_station_name\", \"pickup_hour\", \"rides_t-1\"]])\n",
    "\n",
    "# Sort features by pickup_hour in descending order to ensure the most recent hour is selected\n",
    "features.sort_values(\"pickup_hour\", ascending=False, inplace=True)\n",
    "\n",
    "# Debugging: Inspect features after sorting\n",
    "print(\"\\nfeatures (after sorting):\")\n",
    "print(\"Shape:\", features.shape)\n",
    "print(\"pickup_hour range:\", features[\"pickup_hour\"].min(), \"to\", features[\"pickup_hour\"].max())\n",
    "print(features[[\"start_station_name\", \"pickup_hour\", \"rides_t-1\"]])\n",
    "\n",
    "# Filter features for the most recent hour\n",
    "features_next_hour = features.groupby(\"start_station_name\").first().reset_index()\n",
    "recent_hour = features_next_hour[\"pickup_hour\"].max()\n",
    "print(f\"\\nMost recent hour in features_next_hour: {recent_hour}\")\n",
    "\n",
    "# Debugging: Print features_next_hour\n",
    "print(\"\\nfeatures_next_hour:\")\n",
    "print(\"Shape:\", features_next_hour.shape)\n",
    "print(features_next_hour)\n",
    "\n",
    "# Define the list of models and corresponding feature group names\n",
    "models = [\n",
    "    \"baseline_previous_hour\",\n",
    "    \"lightgbm_28days_lags\",\n",
    "    \"lightgbm_top10_features\",\n",
    "    \"gradient_boosting_temporal_features\",\n",
    "    \"lightgbm_enhanced_lags_cyclic_temporal_interactions\"\n",
    "]\n",
    "\n",
    "prediction_feature_groups = {\n",
    "    \"baseline_previous_hour\": \"predictions_model_baseline\",\n",
    "    \"lightgbm_28days_lags\": \"predictions_model_lgbm_28days\",\n",
    "    \"lightgbm_top10_features\": \"predictions_model_lgbm_top10\",\n",
    "    \"gradient_boosting_temporal_features\": \"predictions_model_gbt\",\n",
    "    \"lightgbm_enhanced_lags_cyclic_temporal_interactions\": \"predictions_model_lgbm_enhanced\"\n",
    "}\n",
    "\n",
    "# Make predictions with each model and save to separate feature groups\n",
    "for model_name in models:\n",
    "    print(f\"\\nProcessing model: {model_name}\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model_from_registry(model_name=model_name)\n",
    "    \n",
    "    # Make predictions for the most recent hour\n",
    "    predictions = get_model_predictions(model, features_next_hour, model_name=model_name)\n",
    "    predictions[\"pickup_hour\"] = recent_hour  # Use the most recent actual hour\n",
    "    predictions\n",
    "    \n",
    "    # Create or retrieve the feature group for this model's predictions\n",
    "    feature_group = feature_store.get_or_create_feature_group(\n",
    "        name=prediction_feature_groups[model_name],\n",
    "        version=1,\n",
    "        description=f\"Predictions from {model_name} model\",\n",
    "        primary_key=[\"start_station_name\", \"pickup_hour\"],\n",
    "        event_time=\"pickup_hour\",\n",
    "    )\n",
    "    \n",
    "    # Insert the predictions into the feature group\n",
    "    feature_group.insert(predictions, write_options={\"wait_for_job\": False})\n",
    "    print(f\"Saved predictions to feature group: {prediction_feature_groups[model_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import src.config as config\n",
    "from src.inference import get_feature_store\n",
    "from src.inference import load_model_from_registry\n",
    "from src.inference import get_model_predictions\n",
    "from src.inference import BaselineModelPreviousHour\n",
    "\n",
    "# Define the corrected transform_ts_data_info_features function inline\n",
    "def transform_ts_data_info_features(\n",
    "    df, feature_col=\"rides\", window_size=12, step_size=1\n",
    "):\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Input DataFrame is empty. Cannot transform into features.\")\n",
    "\n",
    "    station_names = df[\"start_station_name\"].unique()\n",
    "    transformed_data = []\n",
    "\n",
    "    for station_name in station_names:\n",
    "        try:\n",
    "            station_data = df[df[\"start_station_name\"] == station_name].reset_index(drop=True)\n",
    "            # Explicitly sort by pickup_hour to ensure chronological order\n",
    "            station_data.sort_values(\"pickup_hour\", inplace=True)\n",
    "\n",
    "            values = station_data[feature_col].values\n",
    "            times = station_data[\"pickup_hour\"].values\n",
    "\n",
    "            if len(values) <= window_size:\n",
    "                raise ValueError(\"Not enough data to create even one window.\")\n",
    "\n",
    "            rows = []\n",
    "            # Adjust the loop to include the most recent window\n",
    "            # Start from the last possible index and work backwards\n",
    "            end_idx = len(values) - window_size - 1\n",
    "            if end_idx < 0:\n",
    "                end_idx = 0  # Ensure at least one window if possible\n",
    "            for i in range(end_idx, -1, -step_size):\n",
    "                features = values[i : i + window_size]\n",
    "                target_time = times[i + window_size]\n",
    "                row = np.append(features, [station_name, target_time])\n",
    "                rows.append(row)\n",
    "\n",
    "            feature_columns = [f\"{feature_col}_t-{window_size - i}\" for i in range(window_size)]\n",
    "            all_columns = feature_columns + [\"start_station_name\", \"pickup_hour\"]\n",
    "            transformed_df = pd.DataFrame(rows, columns=all_columns)\n",
    "            transformed_data.append(transformed_df)\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping station_name {station_name}: {str(e)}\")\n",
    "\n",
    "    if not transformed_data:\n",
    "        raise ValueError(\"No data could be transformed.\")\n",
    "\n",
    "    final_df = pd.concat(transformed_data, ignore_index=True)\n",
    "    return final_df\n",
    "\n",
    "# Connect to Hopsworks and get the feature store\n",
    "feature_store = get_feature_store()\n",
    "\n",
    "# Retrieve the feature group with recent data\n",
    "feature_group = feature_store.get_feature_group(\n",
    "    name=\"recent_time_series_hourly_feature_group\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Create or retrieve the feature view for recent data\n",
    "try:\n",
    "    feature_store.create_feature_view(\n",
    "        name=\"citi_bike_recent_hourly_feature_view\",\n",
    "        version=1,\n",
    "        query=feature_group.select_all(),\n",
    "    )\n",
    "    print(f\"Feature view 'citi_bike_recent_hourly_feature_view' (version 1) created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating feature view: {e}\")\n",
    "\n",
    "feature_view = feature_store.get_feature_view(\n",
    "    name=\"citi_bike_recent_hourly_feature_view\",\n",
    "    version=1\n",
    ")\n",
    "\n",
    "# Get the current datetime\n",
    "current_date = pd.Timestamp.now(tz='Etc/UTC')\n",
    "print(f\"Current date: {current_date}\")\n",
    "\n",
    "# Read time-series data from the feature store\n",
    "fetch_data_to = current_date.floor('h')  # Include the current hour\n",
    "fetch_data_from = current_date - timedelta(days=1*29)\n",
    "print(f\"Fetching data from {fetch_data_from} to {fetch_data_to}\")\n",
    "\n",
    "ts_data = feature_view.get_batch_data(\n",
    "    start_time=(fetch_data_from - timedelta(days=1)),\n",
    "    end_time=(fetch_data_to + timedelta(days=1)),\n",
    ")\n",
    "ts_data = ts_data[ts_data.pickup_hour.between(fetch_data_from, fetch_data_to)]\n",
    "ts_data.sort_values([\"start_station_name\", \"pickup_hour\"]).reset_index(drop=True)\n",
    "ts_data.info()\n",
    "\n",
    "ts_data[\"pickup_hour\"] = ts_data[\"pickup_hour\"].dt.tz_localize(None)\n",
    "ts_data.info()\n",
    "\n",
    "# Debugging: Print ts_data to inspect pickup_hour range\n",
    "print(\"\\nts_data (after filtering):\")\n",
    "print(\"Shape:\", ts_data.shape)\n",
    "print(\"pickup_hour range:\", ts_data[\"pickup_hour\"].min(), \"to\", ts_data[\"pickup_hour\"].max())\n",
    "print(ts_data)\n",
    "\n",
    "# Transform the data into features using the inline function\n",
    "features = transform_ts_data_info_features(ts_data, window_size=24*28, step_size=23)\n",
    "\n",
    "# Sort features by pickup_hour in descending order to ensure the most recent hour is selected\n",
    "features.sort_values(\"pickup_hour\", ascending=False, inplace=True)\n",
    "\n",
    "# Debugging: Inspect features after sorting\n",
    "print(\"\\nfeatures (after sorting):\")\n",
    "print(\"Shape:\", features.shape)\n",
    "print(\"pickup_hour range:\", features[\"pickup_hour\"].min(), \"to\", features[\"pickup_hour\"].max())\n",
    "print(features[[\"start_station_name\", \"pickup_hour\", \"rides_t-1\"]])\n",
    "\n",
    "# Filter features for the most recent hour\n",
    "features_next_hour = features.groupby(\"start_station_name\").first().reset_index()\n",
    "recent_hour = features_next_hour[\"pickup_hour\"].max()\n",
    "print(f\"\\nMost recent hour in features_next_hour: {recent_hour}\")\n",
    "\n",
    "# Debugging: Print features_next_hour\n",
    "print(\"\\nfeatures_next_hour:\")\n",
    "print(\"Shape:\", features_next_hour.shape)\n",
    "print(features_next_hour)\n",
    "\n",
    "# Define the list of models and corresponding feature group names\n",
    "models = [\n",
    "    \"baseline_previous_hour\",\n",
    "    \"lightgbm_28days_lags\",\n",
    "    \"lightgbm_top10_features\",\n",
    "    \"gradient_boosting_temporal_features\",\n",
    "    \"lightgbm_enhanced_lags_cyclic_temporal_interactions\"\n",
    "]\n",
    "\n",
    "prediction_feature_groups = {\n",
    "    \"baseline_previous_hour\": \"predictions_model_baseline\",\n",
    "    \"lightgbm_28days_lags\": \"predictions_model_lgbm_28days\",\n",
    "    \"lightgbm_top10_features\": \"predictions_model_lgbm_top10\",\n",
    "    \"gradient_boosting_temporal_features\": \"predictions_model_gbt\",\n",
    "    \"lightgbm_enhanced_lags_cyclic_temporal_interactions\": \"predictions_model_lgbm_enhanced\"\n",
    "}\n",
    "\n",
    "# Make predictions with each model and save to separate feature groups\n",
    "for model_name in models:\n",
    "    print(f\"\\nProcessing model: {model_name}\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model_from_registry(model_name=model_name)\n",
    "    \n",
    "    # Make predictions for the most recent hour\n",
    "    predictions = get_model_predictions(model, features_next_hour, model_name=model_name)\n",
    "    predictions[\"pickup_hour\"] = recent_hour  # Use the most recent actual hour\n",
    "    predictions\n",
    "    \n",
    "    # Create or retrieve the feature group for this model's predictions\n",
    "    feature_group = feature_store.get_or_create_feature_group(\n",
    "        name=prediction_feature_groups[model_name],\n",
    "        version=1,\n",
    "        description=f\"Predictions from {model_name} model\",\n",
    "        primary_key=[\"start_station_name\", \"pickup_hour\"],\n",
    "        event_time=\"pickup_hour\",\n",
    "    )\n",
    "    \n",
    "    # Insert the predictions into the feature group\n",
    "    feature_group.insert(predictions, write_options={\"wait_for_job\": False})\n",
    "    print(f\"Saved predictions to feature group: {prediction_feature_groups[model_name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26612685-265e-4415-a149-5751be8f994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current datetime64[us, Etc/UTC]  \n",
    "current_date = pd.Timestamp.now(tz='Etc/UTC')\n",
    "feature_store = get_feature_store()\n",
    "\n",
    "# read time-series data from the feature store\n",
    "fetch_data_to = current_date - timedelta(hours=1)\n",
    "fetch_data_from = current_date - timedelta(days=1*29)\n",
    "print(f\"Fetching data from {fetch_data_from} to {fetch_data_to}\")\n",
    "feature_view = feature_store.get_feature_view(\n",
    "    name=config.FEATURE_VIEW_NAME, version=config.FEATURE_VIEW_VERSION\n",
    ")\n",
    "\n",
    "ts_data = feature_view.get_batch_data(\n",
    "    start_time=(fetch_data_from - timedelta(days=1)),\n",
    "    end_time=(fetch_data_to + timedelta(days=1)),\n",
    ")\n",
    "ts_data = ts_data[ts_data.pickup_hour.between(fetch_data_from, fetch_data_to)]\n",
    "ts_data.sort_values([\"pickup_location_id\", \"pickup_hour\"]).reset_index(drop=True)\n",
    "ts_data[\"pickup_hour\"] = ts_data[\"pickup_hour\"].dt.tz_localize(None)\n",
    "\n",
    "features = transform_ts_data_info_features(ts_data, window_size=24*28, step_size=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22253dce-140a-4296-a48b-35c6c7655b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model_from_registry()\n",
    "predictions = get_model_predictions(model, features)\n",
    "predictions[\"pickup_hour\"] = current_date.ceil('h')\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b171dd4-628a-4c46-af00-92cee476f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_group = get_feature_store().get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_MODEL_PREDICTION,\n",
    "    version=1,\n",
    "    description=\"Predictions from LGBM Model\",\n",
    "    primary_key=[\"pickup_location_id\", \"pickup_hour\"],\n",
    "    event_time=\"pickup_hour\",\n",
    ")\n",
    "feature_group.insert(predictions, write_options={\"wait_for_job\": False})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CDA500PF2)",
   "language": "python",
   "name": "cda500pf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
