{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from src.data_utils import load_and_process_citi_bike_data\n",
    "from src.data_utils import transform_raw_data_into_ts_data\n",
    "import src.config as config  # Import config to use FEATURE_GROUP_NAME and FEATURE_GROUP_VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data using load_and_process function and transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download raw data from 2024 to 2025\n",
      "File already exists for 2024-01.\n",
      "Loading data for 2024-01...\n",
      "Before filtering - 2024-01: 1888085 rows\n",
      "After duration filter - 2024-01: 1884640 rows\n",
      "After station filter - 2024-01: 1886925 rows\n",
      "After date range filter - 2024-01: 1887675 rows\n",
      "Total records: 1,888,085\n",
      "Valid records: 1,883,159\n",
      "Records dropped: 4,926 (0.26%)\n",
      "Successfully processed data for 2024-01.\n",
      "File already exists for 2024-02.\n",
      "Loading data for 2024-02...\n",
      "Before filtering - 2024-02: 2121501 rows\n",
      "After duration filter - 2024-02: 2118148 rows\n",
      "After station filter - 2024-02: 2119635 rows\n",
      "After date range filter - 2024-02: 2121268 rows\n",
      "Total records: 2,121,501\n",
      "Valid records: 2,116,154\n",
      "Records dropped: 5,347 (0.25%)\n",
      "Successfully processed data for 2024-02.\n",
      "File already exists for 2024-03.\n",
      "Loading data for 2024-03...\n",
      "Before filtering - 2024-03: 2663295 rows\n",
      "After duration filter - 2024-03: 2656656 rows\n",
      "After station filter - 2024-03: 2660499 rows\n",
      "After date range filter - 2024-03: 2663057 rows\n",
      "Total records: 2,663,295\n",
      "Valid records: 2,653,773\n",
      "Records dropped: 9,522 (0.36%)\n",
      "Successfully processed data for 2024-03.\n",
      "File already exists for 2024-04.\n",
      "Loading data for 2024-04...\n",
      "Before filtering - 2024-04: 3217063 rows\n",
      "After duration filter - 2024-04: 3206852 rows\n",
      "After station filter - 2024-04: 3214557 rows\n",
      "After date range filter - 2024-04: 3216704 rows\n",
      "Total records: 3,217,063\n",
      "Valid records: 3,204,238\n",
      "Records dropped: 12,825 (0.40%)\n",
      "Successfully processed data for 2024-04.\n",
      "File already exists for 2024-05.\n",
      "Loading data for 2024-05...\n",
      "Before filtering - 2024-05: 4230360 rows\n",
      "After duration filter - 2024-05: 4121339 rows\n",
      "After station filter - 2024-05: 4228630 rows\n",
      "After date range filter - 2024-05: 4230360 rows\n",
      "Total records: 4,230,360\n",
      "Valid records: 4,119,742\n",
      "Records dropped: 110,618 (2.61%)\n",
      "Successfully processed data for 2024-05.\n",
      "File already exists for 2024-06.\n",
      "Loading data for 2024-06...\n",
      "Before filtering - 2024-06: 4783576 rows\n",
      "After duration filter - 2024-06: 4765255 rows\n",
      "After station filter - 2024-06: 4781821 rows\n",
      "After date range filter - 2024-06: 4782235 rows\n",
      "Total records: 4,783,576\n",
      "Valid records: 4,762,418\n",
      "Records dropped: 21,158 (0.44%)\n",
      "Successfully processed data for 2024-06.\n",
      "File already exists for 2024-07.\n",
      "Loading data for 2024-07...\n",
      "Before filtering - 2024-07: 4722896 rows\n",
      "After duration filter - 2024-07: 4705914 rows\n",
      "After station filter - 2024-07: 4720256 rows\n",
      "After date range filter - 2024-07: 4722196 rows\n",
      "Total records: 4,722,896\n",
      "Valid records: 4,702,791\n",
      "Records dropped: 20,105 (0.43%)\n",
      "Successfully processed data for 2024-07.\n",
      "File already exists for 2024-08.\n",
      "Loading data for 2024-08...\n",
      "Before filtering - 2024-08: 4603575 rows\n",
      "After duration filter - 2024-08: 4587138 rows\n",
      "After station filter - 2024-08: 4600613 rows\n",
      "After date range filter - 2024-08: 4602819 rows\n",
      "Total records: 4,603,575\n",
      "Valid records: 4,583,673\n",
      "Records dropped: 19,902 (0.43%)\n",
      "Successfully processed data for 2024-08.\n",
      "File already exists for 2024-09.\n",
      "Loading data for 2024-09...\n",
      "Before filtering - 2024-09: 4997898 rows\n",
      "After duration filter - 2024-09: 4984836 rows\n",
      "After station filter - 2024-09: 4993438 rows\n",
      "After date range filter - 2024-09: 4996775 rows\n",
      "Total records: 4,997,898\n",
      "Valid records: 4,979,583\n",
      "Records dropped: 18,315 (0.37%)\n",
      "Successfully processed data for 2024-09.\n",
      "File already exists for 2024-10.\n",
      "Loading data for 2024-10...\n",
      "Before filtering - 2024-10: 5150054 rows\n",
      "After duration filter - 2024-10: 5138496 rows\n",
      "After station filter - 2024-10: 5145472 rows\n",
      "After date range filter - 2024-10: 5149541 rows\n",
      "Total records: 5,150,054\n",
      "Valid records: 5,133,531\n",
      "Records dropped: 16,523 (0.32%)\n",
      "Successfully processed data for 2024-10.\n",
      "File already exists for 2024-11.\n",
      "Loading data for 2024-11...\n",
      "Before filtering - 2024-11: 3710134 rows\n",
      "After duration filter - 2024-11: 3703540 rows\n",
      "After station filter - 2024-11: 3707833 rows\n",
      "After date range filter - 2024-11: 3708958 rows\n",
      "Total records: 3,710,134\n",
      "Valid records: 3,700,279\n",
      "Records dropped: 9,855 (0.27%)\n",
      "Successfully processed data for 2024-11.\n",
      "File already exists for 2024-12.\n",
      "Loading data for 2024-12...\n",
      "Before filtering - 2024-12: 2311171 rows\n",
      "After duration filter - 2024-12: 2308841 rows\n",
      "After station filter - 2024-12: 2310051 rows\n",
      "After date range filter - 2024-12: 2310900 rows\n",
      "Total records: 2,311,171\n",
      "Valid records: 2,307,489\n",
      "Records dropped: 3,682 (0.16%)\n",
      "Successfully processed data for 2024-12.\n",
      "Combining all monthly data...\n",
      "Data loading and processing complete!\n",
      "File already exists for 2025-01.\n",
      "Loading data for 2025-01...\n",
      "Before filtering - 2025-01: 2124475 rows\n",
      "After duration filter - 2025-01: 2122991 rows\n",
      "After station filter - 2025-01: 2123911 rows\n",
      "After date range filter - 2025-01: 2124268 rows\n",
      "Total records: 2,124,475\n",
      "Valid records: 2,122,262\n",
      "Records dropped: 2,213 (0.10%)\n",
      "Successfully processed data for 2025-01.\n",
      "File already exists for 2025-02.\n",
      "Loading data for 2025-02...\n",
      "Before filtering - 2025-02: 2031257 rows\n",
      "After duration filter - 2025-02: 2029581 rows\n",
      "After station filter - 2025-02: 2030584 rows\n",
      "After date range filter - 2025-02: 2030984 rows\n",
      "Total records: 2,031,257\n",
      "Valid records: 2,028,650\n",
      "Records dropped: 2,607 (0.13%)\n",
      "Successfully processed data for 2025-02.\n",
      "File already exists for 2025-03.\n",
      "Loading data for 2025-03...\n",
      "Before filtering - 2025-03: 3168271 rows\n",
      "After duration filter - 2025-03: 3163453 rows\n",
      "After station filter - 2025-03: 3167218 rows\n",
      "After date range filter - 2025-03: 3167861 rows\n",
      "Total records: 3,168,271\n",
      "Valid records: 3,162,028\n",
      "Records dropped: 6,243 (0.20%)\n",
      "Successfully processed data for 2025-03.\n",
      "Combining all monthly data...\n",
      "Data loading and processing complete!\n",
      "Data loading complete.\n",
      "Inspecting rides DataFrame before transformation:\n",
      "          pickup_datetime                ended_at  \\\n",
      "0 2024-01-22 18:43:19.012 2024-01-22 18:48:10.708   \n",
      "1 2024-01-11 19:19:18.721 2024-01-11 19:47:36.007   \n",
      "2 2024-01-30 19:17:41.693 2024-01-30 19:32:49.857   \n",
      "3 2024-01-27 11:27:01.759 2024-01-27 11:38:01.213   \n",
      "4 2024-01-16 15:15:41.000 2024-01-16 15:29:26.156   \n",
      "\n",
      "                   start_station_name               duration  \n",
      "0  Frederick Douglass Blvd & W 145 St 0 days 00:04:51.696000  \n",
      "1                     W 54 St & 6 Ave 0 days 00:28:17.286000  \n",
      "2                     E 11 St & Ave B 0 days 00:15:08.164000  \n",
      "3                     W 54 St & 6 Ave 0 days 00:10:59.454000  \n",
      "4               Madison Ave & E 99 St 0 days 00:13:45.156000  \n",
      "Number of rows in rides: 51459770\n",
      "pickup_datetime range: 2024-01-01 00:00:03.208000 to 2025-03-31 23:56:56.495000\n",
      "Unique start_station_name values: 2285\n",
      "pickup_datetime dtype: datetime64[ns]\n",
      "start_station_name dtype: object\n",
      "Sample start_station_name values: ['Frederick Douglass Blvd & W 145 St', 'W 54 St & 6 Ave', 'E 11 St & Ave B', 'W 54 St & 6 Ave', 'Madison Ave & E 99 St']\n",
      "After creating pickup_hour:\n",
      "pickup_hour range: 2024-01-01 00:00:00 to 2025-03-31 23:00:00\n",
      "Any NaN in pickup_hour: 0\n",
      "Any NaN in start_station_name: 0\n",
      "pickup_hour dtype: datetime64[ns]\n",
      "After groupby().size():\n",
      "Number of groups: 11544851\n",
      "Sample groups:\n",
      "pickup_hour  start_station_name\n",
      "2024-01-01   1 Ave & E 16 St       3\n",
      "             1 Ave & E 18 St       1\n",
      "             1 Ave & E 30 St       5\n",
      "             1 Ave & E 44 St       1\n",
      "             1 Ave & E 6 St        5\n",
      "dtype: int64\n",
      "After filtering to top 3 stations:\n",
      "Number of rows: 32832\n",
      "Unique start_station_name values: 3\n",
      "Stations retained: <StringArray>\n",
      "['8 Ave & W 31 St', 'University Pl & E 14 St', 'W 21 St & 6 Ave']\n",
      "Length: 3, dtype: string\n"
     ]
    }
   ],
   "source": [
    "# Define the range of years to process\n",
    "from_year = 2024\n",
    "to_year = 2025\n",
    "print(f\"Download raw data from {from_year} to {to_year}\")\n",
    "\n",
    "rides = pd.DataFrame()\n",
    "chunks = []\n",
    "for year in range(from_year, to_year + 1):\n",
    "    # For 2024, process all 12 months\n",
    "    # For 2025, process only January to March (as per original data loading in 05_transform_raw_data_into_features_and_targets.ipynb)\n",
    "    months = list(range(1, 13)) if year == 2024 else list(range(1, 4))\n",
    "    rides_one_year = load_and_process_citi_bike_data(year=year, months=months)\n",
    "    chunks.append(rides_one_year)\n",
    "\n",
    "# Concatenate all chunks\n",
    "rides = pd.concat(chunks, ignore_index=True)\n",
    "print(\"Data loading complete.\")\n",
    "\n",
    "# Transform raw data into time series format\n",
    "ts_data = transform_raw_data_into_ts_data(rides)\n",
    "\n",
    "# Set up MLflow tracking for DagsHub\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = os.getenv(\"MLFLOW_TRACKING_USERNAME\")\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = os.getenv(\"MLFLOW_TRACKING_PASSWORD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logging into Hopsworks, and specifically into project CDA500P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 03:01:09,611 INFO: Initializing external client\n",
      "2025-05-10 03:01:09,621 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.5 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 03:01:10,608 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1225907\n",
      "Successfully connected to Hopsworks project: CDA500PF1\n"
     ]
    }
   ],
   "source": [
    "# Connect to Hopsworks\n",
    "api_key = os.getenv('HOPSWORKS_API_KEY')\n",
    "project_name = os.getenv('HOPSWORKS_PROJECT_NAME')\n",
    "\n",
    "project = hopsworks.login(\n",
    "    api_key_value=api_key,\n",
    "    project=project_name\n",
    ")\n",
    "print(f\"Successfully connected to Hopsworks project: {project_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up pointers, Feature groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or retrieve a feature group in Hopsworks\n",
    "feature_store = project.get_feature_store()\n",
    "\n",
    "feature_group = feature_store.get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,  # Use config.FEATURE_GROUP_NAME\n",
    "    version=config.FEATURE_GROUP_VERSION,  # Use config.FEATURE_GROUP_VERSION\n",
    "    description=\"Time series data at hourly frequency\",\n",
    "    primary_key=[\"start_station_name\", \"pickup_hour\"],\n",
    "    event_time=\"pickup_hour\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |██████████| Rows 32832/32832 | Elapsed Time: 00:02 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: citi_bike_hourly_feature_group_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1225907/jobs/named/citi_bike_hourly_feature_group_1_offline_fg_materialization/executions\n",
      "DataFrame size: 4960.43 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32832 entries, 0 to 32831\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   pickup_hour         32832 non-null  datetime64[ns]\n",
      " 1   start_station_name  32832 non-null  string        \n",
      " 2   rides               32832 non-null  int16         \n",
      "dtypes: datetime64[ns](1), int16(1), string(1)\n",
      "memory usage: 577.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Upload the time series data to the feature group\n",
    "feature_group.insert(ts_data, write_options={\"wait_for_job\": False})\n",
    "\n",
    "# Print memory usage and data info for diagnostics\n",
    "df_memory_mb = rides.memory_usage(deep=True).sum() / (1024 * 1024)\n",
    "print(f\"DataFrame size: {df_memory_mb:.2f} MB\")\n",
    "ts_data.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CDA500PF2)",
   "language": "python",
   "name": "cda500pf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
