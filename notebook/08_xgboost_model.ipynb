{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from src.config import TRANSFORMED_DATA_DIR\n",
    "from src.data_utils import split_time_series_data\n",
    "from src.experiment_utils import set_mlflow_tracking, log_model_to_mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading and Test Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24336, 674)\n",
      "(24336,)\n",
      "(2232, 674)\n",
      "(2232,)\n"
     ]
    }
   ],
   "source": [
    "# Load the tabular data\n",
    "df = pd.read_parquet(TRANSFORMED_DATA_DIR / \"tabular_data.parquet\")\n",
    "df.head(5)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Training period: January 2024 to August 2024\n",
    "# Test period: September 2024 to January 2025\n",
    "X_train, y_train, X_test, y_test = split_time_series_data(\n",
    "    df,\n",
    "    cutoff_date=datetime(2025, 1, 1, 0, 0, 0),\n",
    "    target_column=\"target\"\n",
    ")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# Select only the numeric features (lagged ride counts)\n",
    "past_ride_columns = [c for c in X_train.columns if c.startswith(\"rides_\")]\n",
    "X_train_only_numeric = X_train[past_ride_columns]\n",
    "X_test_only_numeric = X_test[past_ride_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Model Predictions and Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.experiment_utils:MLflow tracking URI and credentials set.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MAE: 3.3661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.experiment_utils:Experiment set to: XGBoost\n",
      "INFO:src.experiment_utils:Logged mean_absolute_error: 3.366122007369995\n",
      "c:\\Users\\singh\\Downloads\\CDS500_Applied_ML_DS\\Projects\\CDA500Final\\CDA500PF2\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "INFO:src.experiment_utils:Model signature inferred.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ddfba6125794e05b5e7479b421ad675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/01 00:02:45 INFO mlflow.models.model: Found the following environment variables used during model inference: [HOPSWORKS_API_KEY]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "Registered model 'XGBRegressor' already exists. Creating a new version of this model...\n",
      "2025/05/01 00:03:01 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGBRegressor, version 2\n",
      "Created version '2' of model 'XGBRegressor'.\n",
      "INFO:src.experiment_utils:Model logged with name: XGBRegressor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run righteous-ray-764 at: https://dagshub.com/singhvarun0405/CDA500PF1.mlflow/#/experiments/3/runs/e5b0b97dc6fe443a8c0fb3ab8609593e\n",
      "🧪 View experiment at: https://dagshub.com/singhvarun0405/CDA500PF1.mlflow/#/experiments/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x217f56d2fc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train an XGBoost model\n",
    "model = xgb.XGBRegressor(max_depth=10)\n",
    "model.fit(X_train_only_numeric, y_train)\n",
    "\n",
    "# Make predictions and evaluate\n",
    "predictions = model.predict(X_test_only_numeric)\n",
    "test_mae = mean_absolute_error(y_test, predictions)\n",
    "print(f\"XGBoost MAE: {test_mae:.4f}\")\n",
    "\n",
    "# Log the model to MLflow\n",
    "mlflow = set_mlflow_tracking()\n",
    "log_model_to_mlflow(model, X_test_only_numeric, \"XGBoost\", \"mean_absolute_error\", score=test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Safe MAPE (non-zero actuals): 59.4620%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def safe_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    # Only compute MAPE for non-zero actual values to avoid division by zero issues\n",
    "    non_zero_mask = y_true != 0\n",
    "    if not np.any(non_zero_mask):\n",
    "        return np.nan  # Return NaN if all actual values are 0\n",
    "    y_true_non_zero = y_true[non_zero_mask]\n",
    "    y_pred_non_zero = y_pred[non_zero_mask]\n",
    "    # Add a small epsilon to the denominator for numerical stability\n",
    "    epsilon = 1e-2  # Larger epsilon to prevent extreme values\n",
    "    mape = np.mean(np.abs((y_true_non_zero - y_pred_non_zero) / (y_true_non_zero + epsilon))) * 100\n",
    "    return mape\n",
    "\n",
    "mape = safe_mean_absolute_percentage_error(y_test, predictions)\n",
    "print(f\"XGBoost Safe MAPE (non-zero actuals): {mape:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MAE (recomputed): 3.3661\n",
      "\n",
      "Distribution of Percentage Errors (non-zero actuals):\n",
      "count    1879.000000\n",
      "mean       59.461965\n",
      "std        90.834545\n",
      "min         0.005991\n",
      "25%        15.250596\n",
      "50%        33.244406\n",
      "75%        67.250652\n",
      "max      1613.194494\n",
      "Name: target, dtype: float64\n",
      "\n",
      "Distribution of Actual Ride Counts in Test Set:\n",
      "count    2232.000000\n",
      "mean        9.217294\n",
      "std         9.269306\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%         7.000000\n",
      "75%        14.000000\n",
      "max        53.000000\n",
      "Name: target, dtype: float64\n",
      "\n",
      "Distribution of Non-Zero Actual Ride Counts in Test Set:\n",
      "count    1879.000000\n",
      "mean       10.948909\n",
      "std         9.115958\n",
      "min         1.000000\n",
      "25%         4.000000\n",
      "50%         9.000000\n",
      "75%        16.000000\n",
      "max        53.000000\n",
      "Name: target, dtype: float64\n",
      "\n",
      "Visualizing row 1078 (Percentage Error: 108.44%)\n",
      "\n",
      "Visualizing row 252 (Percentage Error: 87.53%)\n",
      "\n",
      "Visualizing row 876 (Percentage Error: 21.35%)\n"
     ]
    }
   ],
   "source": [
    "# Additional diagnostics for high MAPE\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Recompute MAE for reference\n",
    "print(f\"XGBoost MAE (recomputed): {test_mae:.4f}\")\n",
    "\n",
    "# Compute percentage errors for non-zero actuals\n",
    "non_zero_mask = y_test != 0\n",
    "y_test_non_zero = y_test[non_zero_mask]\n",
    "predictions_non_zero = predictions[non_zero_mask]\n",
    "percentage_errors = np.abs((y_test_non_zero - predictions_non_zero) / (y_test_non_zero + 1e-2)) * 100\n",
    "\n",
    "# Analyze the distribution of percentage errors\n",
    "print(\"\\nDistribution of Percentage Errors (non-zero actuals):\")\n",
    "print(pd.Series(percentage_errors).describe())\n",
    "\n",
    "# Analyze the distribution of actual ride counts in the test set\n",
    "print(\"\\nDistribution of Actual Ride Counts in Test Set:\")\n",
    "print(y_test.describe())\n",
    "\n",
    "# Analyze the distribution of actual ride counts for non-zero values\n",
    "print(\"\\nDistribution of Non-Zero Actual Ride Counts in Test Set:\")\n",
    "print(y_test_non_zero.describe())\n",
    "\n",
    "# Visualize predictions for a few rows to inspect errors\n",
    "from src.plot_utils import plot_aggregated_time_series\n",
    "\n",
    "# Select a few rows to visualize (e.g., rows with high percentage errors)\n",
    "high_error_indices = np.argsort(percentage_errors)[-3:]  # Top 3 highest percentage errors\n",
    "for idx in high_error_indices:\n",
    "    original_idx = y_test_non_zero.index[idx]\n",
    "    print(f\"\\nVisualizing row {original_idx} (Percentage Error: {percentage_errors[idx]:.2f}%)\")\n",
    "    plot_aggregated_time_series(X_test, y_test, original_idx, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CDA500PF2)",
   "language": "python",
   "name": "cda500pf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
