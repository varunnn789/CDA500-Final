{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_raw_data(year: int, month: int) -> str:\n",
    "    \"\"\"\n",
    "    Fetches raw Citi Bike trip data for a given year and month from the S3 bucket,\n",
    "    extracts the ZIP file, combines CSVs if multiple, and saves as a parquet file.\n",
    "\n",
    "    Args:\n",
    "        year (int): The year to fetch data for (e.g., 2024).\n",
    "        month (int): The month to fetch data for (e.g., 1 for January).\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the saved parquet file.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If the URL is not available or data cannot be processed.\n",
    "    \"\"\"\n",
    "    # Construct the URL for the Citi Bike data (monthly files from 2024 onward)\n",
    "    url = f\"https://s3.amazonaws.com/tripdata/{year}{month:02}-citibike-tripdata.csv.zip\"\n",
    "    \n",
    "    # Send a request to download the ZIP file\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"{url} is not available\")\n",
    "\n",
    "    # Create the directory for raw data if it doesn't exist\n",
    "    raw_data_dir = Path(\"..\") / \"data\" / \"raw\"\n",
    "    raw_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Path to save the combined data as parquet\n",
    "    output_path = raw_data_dir / f\"rides_{year}_{month:02}.parquet\"\n",
    "\n",
    "    try:\n",
    "        # Expected columns based on Citi Bike schema\n",
    "        expected_columns = [\n",
    "            'ride_id', 'rideable_type', 'started_at', 'ended_at',\n",
    "            'start_station_name', 'start_station_id', 'end_station_name', 'end_station_id',\n",
    "            'start_lat', 'start_lng', 'end_lat', 'end_lng', 'member_casual'\n",
    "        ]\n",
    "\n",
    "        # Extract the ZIP file content\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "            # List all CSV files in the ZIP\n",
    "            csv_files = [f for f in z.namelist() if f.endswith('.csv')]\n",
    "            if not csv_files:\n",
    "                raise Exception(f\"No CSV files found in {url}\")\n",
    "\n",
    "            # Read and combine all CSVs into a single DataFrame\n",
    "            dfs = []\n",
    "            for csv_file in csv_files:\n",
    "                with z.open(csv_file) as f:\n",
    "                    # Use 'latin1' encoding to handle special characters; skip bad lines if necessary\n",
    "                    df = pd.read_csv(f, encoding='latin1', on_bad_lines='skip')\n",
    "                    # Keep only the expected columns, drop any extras like 'Unnamed: 0', 'Unnamed: 1'\n",
    "                    df = df[[col for col in expected_columns if col in df.columns]]\n",
    "                    dfs.append(df)\n",
    "\n",
    "            # Combine all CSVs into one DataFrame\n",
    "            combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "        # Inspect the DataFrame for debugging\n",
    "        print(\"DataFrame info before cleaning:\")\n",
    "        print(combined_df.info())\n",
    "        print(\"\\nUnique values in start_station_id:\")\n",
    "        print(combined_df['start_station_id'].unique()[:10])  # Show first 10 unique values\n",
    "\n",
    "        # Clean the data: Convert start_station_id and end_station_id to strings, handle NaN\n",
    "        combined_df['start_station_id'] = combined_df['start_station_id'].astype(str).replace('nan', '')\n",
    "        combined_df['end_station_id'] = combined_df['end_station_id'].astype(str).replace('nan', '')\n",
    "\n",
    "        # Convert started_at and ended_at to datetime\n",
    "        combined_df['started_at'] = pd.to_datetime(combined_df['started_at'], errors='coerce')\n",
    "        combined_df['ended_at'] = pd.to_datetime(combined_df['ended_at'], errors='coerce')\n",
    "\n",
    "        # Ensure other columns are of appropriate types\n",
    "        combined_df['start_lat'] = combined_df['start_lat'].astype(float, errors='ignore')\n",
    "        combined_df['start_lng'] = combined_df['start_lng'].astype(float, errors='ignore')\n",
    "        combined_df['end_lat'] = combined_df['end_lat'].astype(float, errors='ignore')\n",
    "        combined_df['end_lng'] = combined_df['end_lng'].astype(float, errors='ignore')\n",
    "        combined_df['member_casual'] = combined_df['member_casual'].astype(str)\n",
    "\n",
    "        # Inspect the DataFrame after cleaning\n",
    "        print(\"\\nDataFrame info after cleaning:\")\n",
    "        print(combined_df.info())\n",
    "\n",
    "        # Save the combined DataFrame as a parquet file\n",
    "        combined_df.to_parquet(output_path, engine=\"pyarrow\", index=False)\n",
    "        print(f\"Successfully fetched and saved: {str(output_path)}\")\n",
    "        return str(output_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error processing data from {url}: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\singh\\AppData\\Local\\Temp\\ipykernel_43792\\2829821334.py:51: DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f, encoding='latin1', on_bad_lines='skip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame info before cleaning:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1888085 entries, 0 to 1888084\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   ride_id             object \n",
      " 1   rideable_type       object \n",
      " 2   started_at          object \n",
      " 3   ended_at            object \n",
      " 4   start_station_name  object \n",
      " 5   start_station_id    object \n",
      " 6   end_station_name    object \n",
      " 7   end_station_id      object \n",
      " 8   start_lat           float64\n",
      " 9   start_lng           float64\n",
      " 10  end_lat             float64\n",
      " 11  end_lng             float64\n",
      " 12  member_casual       object \n",
      "dtypes: float64(4), object(9)\n",
      "memory usage: 187.3+ MB\n",
      "None\n",
      "\n",
      "Unique values in start_station_id:\n",
      "['7954.12' '6771.13' '5659.11' '7443.01' '4339.01' '4422.05' '7650.05'\n",
      " '6490.02' '5440.05' '7918.12']\n",
      "\n",
      "DataFrame info after cleaning:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1888085 entries, 0 to 1888084\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   ride_id             object        \n",
      " 1   rideable_type       object        \n",
      " 2   started_at          datetime64[ns]\n",
      " 3   ended_at            datetime64[ns]\n",
      " 4   start_station_name  object        \n",
      " 5   start_station_id    object        \n",
      " 6   end_station_name    object        \n",
      " 7   end_station_id      object        \n",
      " 8   start_lat           float64       \n",
      " 9   start_lng           float64       \n",
      " 10  end_lat             float64       \n",
      " 11  end_lng             float64       \n",
      " 12  member_casual       object        \n",
      "dtypes: datetime64[ns](2), float64(4), object(7)\n",
      "memory usage: 187.3+ MB\n",
      "None\n",
      "Successfully fetched and saved: ..\\data\\raw\\rides_2024_01.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'..\\\\data\\\\raw\\\\rides_2024_01.parquet'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function for January 2024\n",
    "fetch_raw_data(2024, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5078F3D302000BD2</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2024-01-22 18:43:19.012</td>\n",
       "      <td>2024-01-22 18:48:10.708</td>\n",
       "      <td>Frederick Douglass Blvd &amp; W 145 St</td>\n",
       "      <td>7954.12</td>\n",
       "      <td>St Nicholas Ave &amp; W 126 St</td>\n",
       "      <td>7756.10</td>\n",
       "      <td>40.823072</td>\n",
       "      <td>-73.941738</td>\n",
       "      <td>40.811432</td>\n",
       "      <td>-73.951878</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>814337105D37302A</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2024-01-11 19:19:18.721</td>\n",
       "      <td>2024-01-11 19:47:36.007</td>\n",
       "      <td>W 54 St &amp; 6 Ave</td>\n",
       "      <td>6771.13</td>\n",
       "      <td>E 74 St &amp; 1 Ave</td>\n",
       "      <td>6953.08</td>\n",
       "      <td>40.761822</td>\n",
       "      <td>-73.977036</td>\n",
       "      <td>40.768974</td>\n",
       "      <td>-73.954823</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A33A920E2B10710C</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2024-01-30 19:17:41.693</td>\n",
       "      <td>2024-01-30 19:32:49.857</td>\n",
       "      <td>E 11 St &amp; Ave B</td>\n",
       "      <td>5659.11</td>\n",
       "      <td>W 10 St &amp; Washington St</td>\n",
       "      <td>5847.06</td>\n",
       "      <td>40.727592</td>\n",
       "      <td>-73.979751</td>\n",
       "      <td>40.733424</td>\n",
       "      <td>-74.008515</td>\n",
       "      <td>casual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3A5FC0DD7D34D74</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2024-01-27 11:27:01.759</td>\n",
       "      <td>2024-01-27 11:38:01.213</td>\n",
       "      <td>W 54 St &amp; 6 Ave</td>\n",
       "      <td>6771.13</td>\n",
       "      <td>E 74 St &amp; 1 Ave</td>\n",
       "      <td>6953.08</td>\n",
       "      <td>40.761779</td>\n",
       "      <td>-73.977144</td>\n",
       "      <td>40.768974</td>\n",
       "      <td>-73.954823</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6F96728ECEFBDAA4</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2024-01-16 15:15:41.000</td>\n",
       "      <td>2024-01-16 15:29:26.156</td>\n",
       "      <td>Madison Ave &amp; E 99 St</td>\n",
       "      <td>7443.01</td>\n",
       "      <td>E 74 St &amp; 1 Ave</td>\n",
       "      <td>6953.08</td>\n",
       "      <td>40.789808</td>\n",
       "      <td>-73.952214</td>\n",
       "      <td>40.768974</td>\n",
       "      <td>-73.954823</td>\n",
       "      <td>member</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type              started_at  \\\n",
       "0  5078F3D302000BD2  electric_bike 2024-01-22 18:43:19.012   \n",
       "1  814337105D37302A  electric_bike 2024-01-11 19:19:18.721   \n",
       "2  A33A920E2B10710C  electric_bike 2024-01-30 19:17:41.693   \n",
       "3  A3A5FC0DD7D34D74  electric_bike 2024-01-27 11:27:01.759   \n",
       "4  6F96728ECEFBDAA4  electric_bike 2024-01-16 15:15:41.000   \n",
       "\n",
       "                 ended_at                  start_station_name  \\\n",
       "0 2024-01-22 18:48:10.708  Frederick Douglass Blvd & W 145 St   \n",
       "1 2024-01-11 19:47:36.007                     W 54 St & 6 Ave   \n",
       "2 2024-01-30 19:32:49.857                     E 11 St & Ave B   \n",
       "3 2024-01-27 11:38:01.213                     W 54 St & 6 Ave   \n",
       "4 2024-01-16 15:29:26.156               Madison Ave & E 99 St   \n",
       "\n",
       "  start_station_id            end_station_name end_station_id  start_lat  \\\n",
       "0          7954.12  St Nicholas Ave & W 126 St        7756.10  40.823072   \n",
       "1          6771.13             E 74 St & 1 Ave        6953.08  40.761822   \n",
       "2          5659.11     W 10 St & Washington St        5847.06  40.727592   \n",
       "3          6771.13             E 74 St & 1 Ave        6953.08  40.761779   \n",
       "4          7443.01             E 74 St & 1 Ave        6953.08  40.789808   \n",
       "\n",
       "   start_lng    end_lat    end_lng member_casual  \n",
       "0 -73.941738  40.811432 -73.951878        member  \n",
       "1 -73.977036  40.768974 -73.954823        member  \n",
       "2 -73.979751  40.733424 -74.008515        casual  \n",
       "3 -73.977144  40.768974 -73.954823        member  \n",
       "4 -73.952214  40.768974 -73.954823        member  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../data/raw/rides_2024_01.parquet\")\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CDA500PF2)",
   "language": "python",
   "name": "cda500pf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
